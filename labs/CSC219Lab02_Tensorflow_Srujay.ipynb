{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "nmRbsTruPxoj",
        "32Isw4lSQQhJ",
        "j-F2fEq5TGR3"
      ],
      "mount_file_id": "183uPTiIGKE2BQU2dcleKkr_5WxtXA-Gx",
      "authorship_tag": "ABX9TyOznrzAZElQ/P6VaqegZ+0q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srujayreddyv/CSUS-CSC219-MachineLeaning/blob/main/labs/CSC219Lab02_Tensorflow_Srujay.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CSC 219 Machine Learning (Fall 2023)"
      ],
      "metadata": {
        "id": "BYq0gmlZPhxM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lab 2: Tensorflow Introduction"
      ],
      "metadata": {
        "id": "70c9Wrb2Ph6D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.0 Helpful functions for Tensorflow (little gems)"
      ],
      "metadata": {
        "id": "nmRbsTruPxoj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following functions will be used with TensorFlow to help preprocess the data.  They allow you to build the feature vector for a neural network.\n",
        "\n",
        "* Predictors/Inputs\n",
        "    * Fill any missing inputs with the median for that column.  Use **missing_median**.\n",
        "    * Encode textual/categorical values with **encode_text_dummy**.\n",
        "    * Encode numeric values with **encode_numeric_zscore**.\n",
        "* Output\n",
        "    * Discard rows with missing outputs.\n",
        "    * Encode textual/categorical values with **encode_text_index**.\n",
        "    * Do not encode output numeric values.\n",
        "* Produce final feature vectors (x) and expected output (y) with **to_xy**."
      ],
      "metadata": {
        "id": "-YVUFHIvP5b8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQxqTt5CPUlD"
      },
      "outputs": [],
      "source": [
        "from collections.abc import Sequence\n",
        "from sklearn import preprocessing\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "\n",
        "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
        "def encode_text_dummy(df, name):\n",
        "    dummies = pd.get_dummies(df[name])\n",
        "    for x in dummies.columns:\n",
        "        dummy_name = \"{}-{}\".format(name, x)\n",
        "        df[dummy_name] = dummies[x]\n",
        "    df.drop(name, axis=1, inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
        "def encode_text_index(df, name):\n",
        "    le = preprocessing.LabelEncoder()\n",
        "    df[name] = le.fit_transform(df[name])\n",
        "    return le.classes_\n",
        "\n",
        "\n",
        "# Encode a numeric column as zscores\n",
        "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
        "    if mean is None:\n",
        "        mean = df[name].mean()\n",
        "\n",
        "    if sd is None:\n",
        "        sd = df[name].std()\n",
        "\n",
        "    df[name] = (df[name] - mean) / sd\n",
        "\n",
        "\n",
        "# Convert all missing values in the specified column to the median\n",
        "def missing_median(df, name):\n",
        "    med = df[name].median()\n",
        "    df[name] = df[name].fillna(med)\n",
        "\n",
        "\n",
        "# Convert all missing values in the specified column to the default\n",
        "def missing_default(df, name, default_value):\n",
        "    df[name] = df[name].fillna(default_value)\n",
        "\n",
        "\n",
        "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
        "def to_xy(df, target):\n",
        "    result = []\n",
        "    for x in df.columns:\n",
        "        if x != target:\n",
        "            result.append(x)\n",
        "    # find out the type of the target column.\n",
        "    target_type = df[target].dtypes\n",
        "    target_type = target_type[0] if isinstance(target_type, Sequence) else target_type\n",
        "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
        "    if target_type in (np.int64, np.int32):\n",
        "        # Classification\n",
        "        dummies = pd.get_dummies(df[target])\n",
        "        return df[result].values.astype(np.float32), dummies.values.astype(np.float32)\n",
        "    else:\n",
        "        # Regression\n",
        "        return df[result].values.astype(np.float32), df[target].values.astype(np.float32)\n",
        "\n",
        "# Nicely formatted time string\n",
        "def hms_string(sec_elapsed):\n",
        "    h = int(sec_elapsed / (60 * 60))\n",
        "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
        "    s = sec_elapsed % 60\n",
        "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
        "\n",
        "\n",
        "# Regression chart.\n",
        "def chart_regression(pred,y,sort=True):\n",
        "    t = pd.DataFrame({'pred' : pred, 'y' : y.flatten()})\n",
        "    if sort:\n",
        "        t.sort_values(by=['y'],inplace=True)\n",
        "    a = plt.plot(t['y'].tolist(),label='expected')\n",
        "    b = plt.plot(t['pred'].tolist(),label='prediction')\n",
        "    plt.ylabel('output')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Remove all rows where the specified column is +/- sd standard deviations\n",
        "def remove_outliers(df, name, sd):\n",
        "    drop_rows = df.index[(np.abs(df[name] - df[name].mean()) >= (sd * df[name].std()))]\n",
        "    df.drop(drop_rows, axis=0, inplace=True)\n",
        "\n",
        "\n",
        "# Encode a column to a range between normalized_low and normalized_high.\n",
        "def encode_numeric_range(df, name, normalized_low=-1, normalized_high=1,\n",
        "                         data_low=None, data_high=None):\n",
        "    if data_low is None:\n",
        "        data_low = min(df[name])\n",
        "        data_high = max(df[name])\n",
        "\n",
        "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
        "               * (normalized_high - normalized_low) + normalized_low\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Classification or Regression"
      ],
      "metadata": {
        "id": "PnVgm9rYP-nl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neural networks can function in *** classification or regression***:\n",
        "\n",
        "* **Regression** - You expect a number as your neural network's prediction.\n",
        "* **Classification** - You expect a class/category as your neural network's prediction.\n",
        "\n",
        "Regression networks always have a single output neuron.  Classification neural networks have an output neuron for each class.\n",
        "\n",
        "These neurons are grouped into layers:\n",
        "\n",
        "* **Input Layer** - The input layer accepts feature vectors from the dataset.  Input layers usually have a bias neuron.\n",
        "* **Output Layer** - The output from the neural network.  The output layer does not have a bias neuron.\n",
        "* **Hidden Layers** - Layers that occur between the input and output layers.  Each hidden layer will usually have a bias neuron.\n"
      ],
      "metadata": {
        "id": "j6FmmuUHQDkM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What version of TensorFlow do you have?\n",
        "\n",
        "TensorFlow is very new and changing rapidly."
      ],
      "metadata": {
        "id": "yd2ZjkVpQD-v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(\"Tensor Flow Version: {}\".format(tf.__version__))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcY-juhYQNVB",
        "outputId": "5c17e634-6e73-4f15-e2f6-3849ba426033"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor Flow Version: 2.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Example of Tensorflow Regression: MPG Prediction"
      ],
      "metadata": {
        "id": "32Isw4lSQQhJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This example shows how to encode the MPG dataset for regression.  Notice that:\n",
        "\n",
        "* Input has both numeric and categorical\n",
        "* Input has missing values"
      ],
      "metadata": {
        "id": "xP6VeDmCQbDd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "import pandas as pd\n",
        "import io\n",
        "import requests\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "path = \"/content/drive/MyDrive/Colab Notebooks/CSC219-MachineLearning/labs/data\"\n",
        "\n",
        "filename_read = os.path.join(path,\"auto-mpg.csv\")\n",
        "df = pd.read_csv(filename_read,na_values=['NA','?'])\n",
        "\n",
        "df[0:5]"
      ],
      "metadata": {
        "id": "C-9GCKVZRDCH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "f0569eb6-b4e5-4651-8c59-9399cc456614"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    mpg  cylinders  displacement  horsepower  weight  acceleration  year  \\\n",
              "0  18.0          8         307.0       130.0    3504          12.0    70   \n",
              "1  15.0          8         350.0       165.0    3693          11.5    70   \n",
              "2  18.0          8         318.0       150.0    3436          11.0    70   \n",
              "3  16.0          8         304.0       150.0    3433          12.0    70   \n",
              "4  17.0          8         302.0       140.0    3449          10.5    70   \n",
              "\n",
              "   origin                       name  \n",
              "0       1  chevrolet chevelle malibu  \n",
              "1       1          buick skylark 320  \n",
              "2       1         plymouth satellite  \n",
              "3       1              amc rebel sst  \n",
              "4       1                ford torino  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ef5164a5-94dc-4ed7-bf46-30354da986e9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mpg</th>\n",
              "      <th>cylinders</th>\n",
              "      <th>displacement</th>\n",
              "      <th>horsepower</th>\n",
              "      <th>weight</th>\n",
              "      <th>acceleration</th>\n",
              "      <th>year</th>\n",
              "      <th>origin</th>\n",
              "      <th>name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>18.0</td>\n",
              "      <td>8</td>\n",
              "      <td>307.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>3504</td>\n",
              "      <td>12.0</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>chevrolet chevelle malibu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>15.0</td>\n",
              "      <td>8</td>\n",
              "      <td>350.0</td>\n",
              "      <td>165.0</td>\n",
              "      <td>3693</td>\n",
              "      <td>11.5</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>buick skylark 320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>18.0</td>\n",
              "      <td>8</td>\n",
              "      <td>318.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>3436</td>\n",
              "      <td>11.0</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>plymouth satellite</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>16.0</td>\n",
              "      <td>8</td>\n",
              "      <td>304.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>3433</td>\n",
              "      <td>12.0</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>amc rebel sst</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>17.0</td>\n",
              "      <td>8</td>\n",
              "      <td>302.0</td>\n",
              "      <td>140.0</td>\n",
              "      <td>3449</td>\n",
              "      <td>10.5</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>ford torino</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ef5164a5-94dc-4ed7-bf46-30354da986e9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ef5164a5-94dc-4ed7-bf46-30354da986e9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ef5164a5-94dc-4ed7-bf46-30354da986e9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a9415e9f-3afc-42b2-b415-3be97084fc35\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a9415e9f-3afc-42b2-b415-3be97084fc35')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a9415e9f-3afc-42b2-b415-3be97084fc35 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cars = df['name']\n",
        "\n",
        "df.drop('name',1,inplace=True)\n",
        "\n",
        "missing_median(df, 'horsepower')\n",
        "\n",
        "encode_text_dummy(df, 'origin')\n",
        "\n",
        "x,y = to_xy(df,\"mpg\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMFz4zSWSHmm",
        "outputId": "87ec1f3c-219d-4665-b865-b3464f85ed3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-65707f89fc55>:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
            "  df.drop('name',1,inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNRt1yXqSPDF",
        "outputId": "7e6903d7-129e-4810-b239-ba6e66c5a012"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(398, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joTby_0qSSAC",
        "outputId": "9cca053b-3546-487d-8525-89e60fe83652"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(398,)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gDLM6_HSUFz",
        "outputId": "9755767a-9d09-41bb-ad03-753ee13ad368"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  8., 307., 130., ...,   1.,   0.,   0.],\n",
              "       [  8., 350., 165., ...,   1.,   0.,   0.],\n",
              "       [  8., 318., 150., ...,   1.,   0.,   0.],\n",
              "       ...,\n",
              "       [  4., 135.,  84., ...,   1.,   0.,   0.],\n",
              "       [  4., 120.,  79., ...,   1.,   0.,   0.],\n",
              "       [  4., 119.,  82., ...,   1.,   0.,   0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZM6kMfLSVF3",
        "outputId": "7760618e-07b7-4942-fd93-a8a7833c6175"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([18. , 15. , 18. , 16. , 17. , 15. , 14. , 14. , 14. , 15. , 15. ,\n",
              "       14. , 15. , 14. , 24. , 22. , 18. , 21. , 27. , 26. , 25. , 24. ,\n",
              "       25. , 26. , 21. , 10. , 10. , 11. ,  9. , 27. , 28. , 25. , 25. ,\n",
              "       19. , 16. , 17. , 19. , 18. , 14. , 14. , 14. , 14. , 12. , 13. ,\n",
              "       13. , 18. , 22. , 19. , 18. , 23. , 28. , 30. , 30. , 31. , 35. ,\n",
              "       27. , 26. , 24. , 25. , 23. , 20. , 21. , 13. , 14. , 15. , 14. ,\n",
              "       17. , 11. , 13. , 12. , 13. , 19. , 15. , 13. , 13. , 14. , 18. ,\n",
              "       22. , 21. , 26. , 22. , 28. , 23. , 28. , 27. , 13. , 14. , 13. ,\n",
              "       14. , 15. , 12. , 13. , 13. , 14. , 13. , 12. , 13. , 18. , 16. ,\n",
              "       18. , 18. , 23. , 26. , 11. , 12. , 13. , 12. , 18. , 20. , 21. ,\n",
              "       22. , 18. , 19. , 21. , 26. , 15. , 16. , 29. , 24. , 20. , 19. ,\n",
              "       15. , 24. , 20. , 11. , 20. , 21. , 19. , 15. , 31. , 26. , 32. ,\n",
              "       25. , 16. , 16. , 18. , 16. , 13. , 14. , 14. , 14. , 29. , 26. ,\n",
              "       26. , 31. , 32. , 28. , 24. , 26. , 24. , 26. , 31. , 19. , 18. ,\n",
              "       15. , 15. , 16. , 15. , 16. , 14. , 17. , 16. , 15. , 18. , 21. ,\n",
              "       20. , 13. , 29. , 23. , 20. , 23. , 24. , 25. , 24. , 18. , 29. ,\n",
              "       19. , 23. , 23. , 22. , 25. , 33. , 28. , 25. , 25. , 26. , 27. ,\n",
              "       17.5, 16. , 15.5, 14.5, 22. , 22. , 24. , 22.5, 29. , 24.5, 29. ,\n",
              "       33. , 20. , 18. , 18.5, 17.5, 29.5, 32. , 28. , 26.5, 20. , 13. ,\n",
              "       19. , 19. , 16.5, 16.5, 13. , 13. , 13. , 31.5, 30. , 36. , 25.5,\n",
              "       33.5, 17.5, 17. , 15.5, 15. , 17.5, 20.5, 19. , 18.5, 16. , 15.5,\n",
              "       15.5, 16. , 29. , 24.5, 26. , 25.5, 30.5, 33.5, 30. , 30.5, 22. ,\n",
              "       21.5, 21.5, 43.1, 36.1, 32.8, 39.4, 36.1, 19.9, 19.4, 20.2, 19.2,\n",
              "       20.5, 20.2, 25.1, 20.5, 19.4, 20.6, 20.8, 18.6, 18.1, 19.2, 17.7,\n",
              "       18.1, 17.5, 30. , 27.5, 27.2, 30.9, 21.1, 23.2, 23.8, 23.9, 20.3,\n",
              "       17. , 21.6, 16.2, 31.5, 29.5, 21.5, 19.8, 22.3, 20.2, 20.6, 17. ,\n",
              "       17.6, 16.5, 18.2, 16.9, 15.5, 19.2, 18.5, 31.9, 34.1, 35.7, 27.4,\n",
              "       25.4, 23. , 27.2, 23.9, 34.2, 34.5, 31.8, 37.3, 28.4, 28.8, 26.8,\n",
              "       33.5, 41.5, 38.1, 32.1, 37.2, 28. , 26.4, 24.3, 19.1, 34.3, 29.8,\n",
              "       31.3, 37. , 32.2, 46.6, 27.9, 40.8, 44.3, 43.4, 36.4, 30. , 44.6,\n",
              "       40.9, 33.8, 29.8, 32.7, 23.7, 35. , 23.6, 32.4, 27.2, 26.6, 25.8,\n",
              "       23.5, 30. , 39.1, 39. , 35.1, 32.3, 37. , 37.7, 34.1, 34.7, 34.4,\n",
              "       29.9, 33. , 34.5, 33.7, 32.4, 32.9, 31.6, 28.1, 30.7, 25.4, 24.2,\n",
              "       22.4, 26.6, 20.2, 17.6, 28. , 27. , 34. , 31. , 29. , 27. , 24. ,\n",
              "       23. , 36. , 37. , 31. , 38. , 36. , 36. , 36. , 34. , 38. , 32. ,\n",
              "       38. , 25. , 38. , 26. , 22. , 32. , 36. , 27. , 27. , 44. , 32. ,\n",
              "       28. , 31. ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(25, input_dim=x.shape[1], activation='relu')) # Hidden 1     #  why input_dim=x.shape[1]?\n",
        "model.add(Dense(10, activation='relu')) # Hidden 2\n",
        "model.add(Dense(1)) # Output\n",
        "\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "model.fit(x,y,verbose=2,epochs=100)    # Verbosity mode. 0 = silent, 1 = progress bar, 2 = one line per epoch.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUkZaPCvSY17",
        "outputId": "a438e706-9c0c-4e31-98d3-f8e8a639b450"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "13/13 - 1s - loss: 15389.0176 - 624ms/epoch - 48ms/step\n",
            "Epoch 2/100\n",
            "13/13 - 0s - loss: 3643.0308 - 14ms/epoch - 1ms/step\n",
            "Epoch 3/100\n",
            "13/13 - 0s - loss: 744.7773 - 15ms/epoch - 1ms/step\n",
            "Epoch 4/100\n",
            "13/13 - 0s - loss: 501.3780 - 16ms/epoch - 1ms/step\n",
            "Epoch 5/100\n",
            "13/13 - 0s - loss: 432.9582 - 15ms/epoch - 1ms/step\n",
            "Epoch 6/100\n",
            "13/13 - 0s - loss: 380.4862 - 14ms/epoch - 1ms/step\n",
            "Epoch 7/100\n",
            "13/13 - 0s - loss: 365.3225 - 14ms/epoch - 1ms/step\n",
            "Epoch 8/100\n",
            "13/13 - 0s - loss: 340.7126 - 15ms/epoch - 1ms/step\n",
            "Epoch 9/100\n",
            "13/13 - 0s - loss: 338.3392 - 21ms/epoch - 2ms/step\n",
            "Epoch 10/100\n",
            "13/13 - 0s - loss: 324.5045 - 16ms/epoch - 1ms/step\n",
            "Epoch 11/100\n",
            "13/13 - 0s - loss: 308.2317 - 20ms/epoch - 2ms/step\n",
            "Epoch 12/100\n",
            "13/13 - 0s - loss: 298.7678 - 17ms/epoch - 1ms/step\n",
            "Epoch 13/100\n",
            "13/13 - 0s - loss: 287.3769 - 15ms/epoch - 1ms/step\n",
            "Epoch 14/100\n",
            "13/13 - 0s - loss: 278.0823 - 19ms/epoch - 1ms/step\n",
            "Epoch 15/100\n",
            "13/13 - 0s - loss: 269.0443 - 21ms/epoch - 2ms/step\n",
            "Epoch 16/100\n",
            "13/13 - 0s - loss: 260.9413 - 20ms/epoch - 2ms/step\n",
            "Epoch 17/100\n",
            "13/13 - 0s - loss: 247.5254 - 29ms/epoch - 2ms/step\n",
            "Epoch 18/100\n",
            "13/13 - 0s - loss: 237.5608 - 21ms/epoch - 2ms/step\n",
            "Epoch 19/100\n",
            "13/13 - 0s - loss: 228.5703 - 17ms/epoch - 1ms/step\n",
            "Epoch 20/100\n",
            "13/13 - 0s - loss: 222.6955 - 17ms/epoch - 1ms/step\n",
            "Epoch 21/100\n",
            "13/13 - 0s - loss: 211.2140 - 16ms/epoch - 1ms/step\n",
            "Epoch 22/100\n",
            "13/13 - 0s - loss: 199.6218 - 22ms/epoch - 2ms/step\n",
            "Epoch 23/100\n",
            "13/13 - 0s - loss: 189.1029 - 21ms/epoch - 2ms/step\n",
            "Epoch 24/100\n",
            "13/13 - 0s - loss: 182.9964 - 19ms/epoch - 1ms/step\n",
            "Epoch 25/100\n",
            "13/13 - 0s - loss: 170.8387 - 19ms/epoch - 1ms/step\n",
            "Epoch 26/100\n",
            "13/13 - 0s - loss: 164.7323 - 28ms/epoch - 2ms/step\n",
            "Epoch 27/100\n",
            "13/13 - 0s - loss: 151.8745 - 18ms/epoch - 1ms/step\n",
            "Epoch 28/100\n",
            "13/13 - 0s - loss: 145.8012 - 17ms/epoch - 1ms/step\n",
            "Epoch 29/100\n",
            "13/13 - 0s - loss: 141.6034 - 18ms/epoch - 1ms/step\n",
            "Epoch 30/100\n",
            "13/13 - 0s - loss: 131.8789 - 17ms/epoch - 1ms/step\n",
            "Epoch 31/100\n",
            "13/13 - 0s - loss: 127.9308 - 20ms/epoch - 2ms/step\n",
            "Epoch 32/100\n",
            "13/13 - 0s - loss: 115.8257 - 18ms/epoch - 1ms/step\n",
            "Epoch 33/100\n",
            "13/13 - 0s - loss: 112.4392 - 19ms/epoch - 1ms/step\n",
            "Epoch 34/100\n",
            "13/13 - 0s - loss: 104.4361 - 19ms/epoch - 1ms/step\n",
            "Epoch 35/100\n",
            "13/13 - 0s - loss: 96.8414 - 16ms/epoch - 1ms/step\n",
            "Epoch 36/100\n",
            "13/13 - 0s - loss: 93.8750 - 18ms/epoch - 1ms/step\n",
            "Epoch 37/100\n",
            "13/13 - 0s - loss: 86.5673 - 18ms/epoch - 1ms/step\n",
            "Epoch 38/100\n",
            "13/13 - 0s - loss: 79.8447 - 24ms/epoch - 2ms/step\n",
            "Epoch 39/100\n",
            "13/13 - 0s - loss: 75.4937 - 18ms/epoch - 1ms/step\n",
            "Epoch 40/100\n",
            "13/13 - 0s - loss: 70.8672 - 16ms/epoch - 1ms/step\n",
            "Epoch 41/100\n",
            "13/13 - 0s - loss: 67.5764 - 16ms/epoch - 1ms/step\n",
            "Epoch 42/100\n",
            "13/13 - 0s - loss: 62.4492 - 19ms/epoch - 1ms/step\n",
            "Epoch 43/100\n",
            "13/13 - 0s - loss: 58.5057 - 17ms/epoch - 1ms/step\n",
            "Epoch 44/100\n",
            "13/13 - 0s - loss: 56.6977 - 22ms/epoch - 2ms/step\n",
            "Epoch 45/100\n",
            "13/13 - 0s - loss: 52.6191 - 19ms/epoch - 1ms/step\n",
            "Epoch 46/100\n",
            "13/13 - 0s - loss: 49.3557 - 25ms/epoch - 2ms/step\n",
            "Epoch 47/100\n",
            "13/13 - 0s - loss: 45.7557 - 20ms/epoch - 2ms/step\n",
            "Epoch 48/100\n",
            "13/13 - 0s - loss: 43.2049 - 24ms/epoch - 2ms/step\n",
            "Epoch 49/100\n",
            "13/13 - 0s - loss: 40.7475 - 21ms/epoch - 2ms/step\n",
            "Epoch 50/100\n",
            "13/13 - 0s - loss: 40.2136 - 20ms/epoch - 2ms/step\n",
            "Epoch 51/100\n",
            "13/13 - 0s - loss: 39.2117 - 16ms/epoch - 1ms/step\n",
            "Epoch 52/100\n",
            "13/13 - 0s - loss: 35.8684 - 18ms/epoch - 1ms/step\n",
            "Epoch 53/100\n",
            "13/13 - 0s - loss: 33.0034 - 15ms/epoch - 1ms/step\n",
            "Epoch 54/100\n",
            "13/13 - 0s - loss: 31.8313 - 15ms/epoch - 1ms/step\n",
            "Epoch 55/100\n",
            "13/13 - 0s - loss: 30.2240 - 15ms/epoch - 1ms/step\n",
            "Epoch 56/100\n",
            "13/13 - 0s - loss: 28.8732 - 16ms/epoch - 1ms/step\n",
            "Epoch 57/100\n",
            "13/13 - 0s - loss: 27.9178 - 17ms/epoch - 1ms/step\n",
            "Epoch 58/100\n",
            "13/13 - 0s - loss: 26.3724 - 22ms/epoch - 2ms/step\n",
            "Epoch 59/100\n",
            "13/13 - 0s - loss: 25.0573 - 17ms/epoch - 1ms/step\n",
            "Epoch 60/100\n",
            "13/13 - 0s - loss: 24.0986 - 25ms/epoch - 2ms/step\n",
            "Epoch 61/100\n",
            "13/13 - 0s - loss: 23.9538 - 19ms/epoch - 1ms/step\n",
            "Epoch 62/100\n",
            "13/13 - 0s - loss: 23.7239 - 16ms/epoch - 1ms/step\n",
            "Epoch 63/100\n",
            "13/13 - 0s - loss: 22.3141 - 15ms/epoch - 1ms/step\n",
            "Epoch 64/100\n",
            "13/13 - 0s - loss: 21.3979 - 16ms/epoch - 1ms/step\n",
            "Epoch 65/100\n",
            "13/13 - 0s - loss: 21.3288 - 18ms/epoch - 1ms/step\n",
            "Epoch 66/100\n",
            "13/13 - 0s - loss: 20.7098 - 14ms/epoch - 1ms/step\n",
            "Epoch 67/100\n",
            "13/13 - 0s - loss: 20.8038 - 18ms/epoch - 1ms/step\n",
            "Epoch 68/100\n",
            "13/13 - 0s - loss: 20.3106 - 18ms/epoch - 1ms/step\n",
            "Epoch 69/100\n",
            "13/13 - 0s - loss: 19.1458 - 22ms/epoch - 2ms/step\n",
            "Epoch 70/100\n",
            "13/13 - 0s - loss: 18.6986 - 15ms/epoch - 1ms/step\n",
            "Epoch 71/100\n",
            "13/13 - 0s - loss: 18.4877 - 16ms/epoch - 1ms/step\n",
            "Epoch 72/100\n",
            "13/13 - 0s - loss: 18.4628 - 15ms/epoch - 1ms/step\n",
            "Epoch 73/100\n",
            "13/13 - 0s - loss: 18.0770 - 19ms/epoch - 1ms/step\n",
            "Epoch 74/100\n",
            "13/13 - 0s - loss: 18.0603 - 17ms/epoch - 1ms/step\n",
            "Epoch 75/100\n",
            "13/13 - 0s - loss: 17.7729 - 15ms/epoch - 1ms/step\n",
            "Epoch 76/100\n",
            "13/13 - 0s - loss: 18.2586 - 22ms/epoch - 2ms/step\n",
            "Epoch 77/100\n",
            "13/13 - 0s - loss: 17.5010 - 14ms/epoch - 1ms/step\n",
            "Epoch 78/100\n",
            "13/13 - 0s - loss: 17.5718 - 17ms/epoch - 1ms/step\n",
            "Epoch 79/100\n",
            "13/13 - 0s - loss: 18.3366 - 17ms/epoch - 1ms/step\n",
            "Epoch 80/100\n",
            "13/13 - 0s - loss: 17.4796 - 16ms/epoch - 1ms/step\n",
            "Epoch 81/100\n",
            "13/13 - 0s - loss: 17.2268 - 16ms/epoch - 1ms/step\n",
            "Epoch 82/100\n",
            "13/13 - 0s - loss: 17.0500 - 16ms/epoch - 1ms/step\n",
            "Epoch 83/100\n",
            "13/13 - 0s - loss: 16.5598 - 17ms/epoch - 1ms/step\n",
            "Epoch 84/100\n",
            "13/13 - 0s - loss: 16.9251 - 16ms/epoch - 1ms/step\n",
            "Epoch 85/100\n",
            "13/13 - 0s - loss: 16.9657 - 20ms/epoch - 2ms/step\n",
            "Epoch 86/100\n",
            "13/13 - 0s - loss: 17.4374 - 16ms/epoch - 1ms/step\n",
            "Epoch 87/100\n",
            "13/13 - 0s - loss: 16.3332 - 16ms/epoch - 1ms/step\n",
            "Epoch 88/100\n",
            "13/13 - 0s - loss: 16.6645 - 17ms/epoch - 1ms/step\n",
            "Epoch 89/100\n",
            "13/13 - 0s - loss: 16.6394 - 17ms/epoch - 1ms/step\n",
            "Epoch 90/100\n",
            "13/13 - 0s - loss: 16.8819 - 19ms/epoch - 1ms/step\n",
            "Epoch 91/100\n",
            "13/13 - 0s - loss: 15.8837 - 18ms/epoch - 1ms/step\n",
            "Epoch 92/100\n",
            "13/13 - 0s - loss: 16.3847 - 14ms/epoch - 1ms/step\n",
            "Epoch 93/100\n",
            "13/13 - 0s - loss: 17.6964 - 15ms/epoch - 1ms/step\n",
            "Epoch 94/100\n",
            "13/13 - 0s - loss: 16.0659 - 22ms/epoch - 2ms/step\n",
            "Epoch 95/100\n",
            "13/13 - 0s - loss: 15.8457 - 21ms/epoch - 2ms/step\n",
            "Epoch 96/100\n",
            "13/13 - 0s - loss: 16.7154 - 19ms/epoch - 1ms/step\n",
            "Epoch 97/100\n",
            "13/13 - 0s - loss: 15.7892 - 18ms/epoch - 1ms/step\n",
            "Epoch 98/100\n",
            "13/13 - 0s - loss: 16.4837 - 19ms/epoch - 1ms/step\n",
            "Epoch 99/100\n",
            "13/13 - 0s - loss: 15.5280 - 16ms/epoch - 1ms/step\n",
            "Epoch 100/100\n",
            "13/13 - 0s - loss: 15.5152 - 17ms/epoch - 1ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7fd34014dba0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Monitor the loss at each epoch\n",
        "\n",
        "One line is produced for each training epoch.  You can eliminate this output by setting the verbose setting of the fit command:\n",
        "\n",
        "* **verbose=0** - No progress output (use with Juputer if you do not want output)\n",
        "* **verbose=1** - Display progress bar, does not work well with Jupyter\n",
        "* **verbose=2** - Summary progress output (use with Jupyter if you want to know the loss at each epoch)"
      ],
      "metadata": {
        "id": "HBsp9feuScl9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use Trained Model to Make Regression Prediction"
      ],
      "metadata": {
        "id": "anO1LnDISo1V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we will perform actual predictions.  These predictions are assigned to the **pred** variable. These are all MPG predictions from the neural network.  \n",
        "\n",
        "***Notice that the data to predict should be a 2D array!***  \n",
        "\n",
        "***Notice that the prediction result is also a 2D array!***\n",
        "\n",
        "Neural networks can return multiple values, so the result is always an array.  Here the neural network only returns 1 value per prediction (there are 398 cars, so 398 predictions).  However, a 2D array is needed because the neural network has the potential of returning more than one value.\n"
      ],
      "metadata": {
        "id": "9o-4d5yzSgR2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict(x)\n",
        "print(\"Shape: {}\".format(pred.shape))\n",
        "print(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJ_UJfvwSwzQ",
        "outputId": "ccf9e206-1519-401d-d914-ba01b80d5b4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13/13 [==============================] - 0s 1ms/step\n",
            "Shape: (398, 1)\n",
            "[[15.624652 ]\n",
            " [16.035051 ]\n",
            " [17.026726 ]\n",
            " [17.727373 ]\n",
            " [16.564383 ]\n",
            " [12.594571 ]\n",
            " [13.293249 ]\n",
            " [13.448194 ]\n",
            " [13.53947  ]\n",
            " [15.335877 ]\n",
            " [15.657725 ]\n",
            " [15.612835 ]\n",
            " [12.3518305]\n",
            " [20.13923  ]\n",
            " [27.01107  ]\n",
            " [20.66579  ]\n",
            " [21.088102 ]\n",
            " [21.093424 ]\n",
            " [28.053541 ]\n",
            " [27.231878 ]\n",
            " [25.407595 ]\n",
            " [26.298727 ]\n",
            " [27.733406 ]\n",
            " [28.262215 ]\n",
            " [21.022673 ]\n",
            " [15.827463 ]\n",
            " [17.759161 ]\n",
            " [17.862083 ]\n",
            " [16.285208 ]\n",
            " [28.489033 ]\n",
            " [25.650084 ]\n",
            " [27.93977  ]\n",
            " [29.17956  ]\n",
            " [20.813997 ]\n",
            " [18.035563 ]\n",
            " [17.32688  ]\n",
            " [16.46868  ]\n",
            " [18.132235 ]\n",
            " [14.035546 ]\n",
            " [11.820781 ]\n",
            " [13.606902 ]\n",
            " [14.642659 ]\n",
            " [10.383515 ]\n",
            " [10.126098 ]\n",
            " [ 8.597239 ]\n",
            " [19.260326 ]\n",
            " [24.211739 ]\n",
            " [17.45025  ]\n",
            " [17.055342 ]\n",
            " [25.814741 ]\n",
            " [27.837439 ]\n",
            " [28.858444 ]\n",
            " [28.013556 ]\n",
            " [30.195023 ]\n",
            " [31.06391  ]\n",
            " [28.503769 ]\n",
            " [28.24641  ]\n",
            " [28.453825 ]\n",
            " [27.68904  ]\n",
            " [27.348482 ]\n",
            " [26.24245  ]\n",
            " [26.762402 ]\n",
            " [14.150744 ]\n",
            " [12.754073 ]\n",
            " [14.99413  ]\n",
            " [14.057265 ]\n",
            " [17.312021 ]\n",
            " [13.069062 ]\n",
            " [12.52586  ]\n",
            " [13.165567 ]\n",
            " [13.918973 ]\n",
            " [29.477253 ]\n",
            " [16.444338 ]\n",
            " [14.001349 ]\n",
            " [14.462375 ]\n",
            " [15.3884   ]\n",
            " [26.038754 ]\n",
            " [25.903114 ]\n",
            " [24.863594 ]\n",
            " [27.749832 ]\n",
            " [25.821121 ]\n",
            " [29.017862 ]\n",
            " [27.043964 ]\n",
            " [27.051731 ]\n",
            " [29.505747 ]\n",
            " [16.486567 ]\n",
            " [17.747557 ]\n",
            " [14.560454 ]\n",
            " [15.56717  ]\n",
            " [16.97747  ]\n",
            " [11.214501 ]\n",
            " [10.734876 ]\n",
            " [13.752443 ]\n",
            " [15.143654 ]\n",
            " [13.211341 ]\n",
            " [12.470071 ]\n",
            " [17.093164 ]\n",
            " [20.690477 ]\n",
            " [18.990892 ]\n",
            " [20.802204 ]\n",
            " [18.941343 ]\n",
            " [21.73058  ]\n",
            " [28.079878 ]\n",
            " [ 8.541245 ]\n",
            " [10.0688925]\n",
            " [13.007795 ]\n",
            " [14.824572 ]\n",
            " [21.35429  ]\n",
            " [29.600655 ]\n",
            " [25.225603 ]\n",
            " [28.69312  ]\n",
            " [30.349878 ]\n",
            " [27.13457  ]\n",
            " [25.8589   ]\n",
            " [28.936817 ]\n",
            " [14.097267 ]\n",
            " [17.71846  ]\n",
            " [29.383757 ]\n",
            " [27.62192  ]\n",
            " [26.595816 ]\n",
            " [27.011187 ]\n",
            " [18.515642 ]\n",
            " [27.54622  ]\n",
            " [26.424303 ]\n",
            " [18.615213 ]\n",
            " [21.298521 ]\n",
            " [22.334799 ]\n",
            " [21.454458 ]\n",
            " [18.92375  ]\n",
            " [30.526236 ]\n",
            " [26.028793 ]\n",
            " [31.624395 ]\n",
            " [24.672207 ]\n",
            " [16.730536 ]\n",
            " [18.239473 ]\n",
            " [18.701086 ]\n",
            " [15.654044 ]\n",
            " [12.229516 ]\n",
            " [14.2780905]\n",
            " [13.637826 ]\n",
            " [16.166365 ]\n",
            " [29.237476 ]\n",
            " [29.59768  ]\n",
            " [28.025438 ]\n",
            " [30.329733 ]\n",
            " [29.635374 ]\n",
            " [27.861658 ]\n",
            " [29.175152 ]\n",
            " [27.29865  ]\n",
            " [28.107124 ]\n",
            " [28.770197 ]\n",
            " [29.523636 ]\n",
            " [19.922354 ]\n",
            " [18.949478 ]\n",
            " [17.439806 ]\n",
            " [18.46542  ]\n",
            " [12.144319 ]\n",
            " [13.420263 ]\n",
            " [14.728232 ]\n",
            " [12.456708 ]\n",
            " [18.87438  ]\n",
            " [17.332273 ]\n",
            " [18.408648 ]\n",
            " [18.004488 ]\n",
            " [21.85274  ]\n",
            " [19.378233 ]\n",
            " [19.538479 ]\n",
            " [29.280153 ]\n",
            " [25.290512 ]\n",
            " [21.82585  ]\n",
            " [25.434141 ]\n",
            " [26.615993 ]\n",
            " [28.930132 ]\n",
            " [28.733438 ]\n",
            " [22.952364 ]\n",
            " [29.715488 ]\n",
            " [19.752665 ]\n",
            " [27.428362 ]\n",
            " [25.819551 ]\n",
            " [26.12956  ]\n",
            " [28.667795 ]\n",
            " [29.842127 ]\n",
            " [28.630487 ]\n",
            " [29.42181  ]\n",
            " [26.344769 ]\n",
            " [28.84754  ]\n",
            " [29.831753 ]\n",
            " [15.843286 ]\n",
            " [16.356876 ]\n",
            " [15.666627 ]\n",
            " [15.249602 ]\n",
            " [20.793753 ]\n",
            " [19.582392 ]\n",
            " [21.627974 ]\n",
            " [20.939178 ]\n",
            " [29.112236 ]\n",
            " [28.67987  ]\n",
            " [30.19433  ]\n",
            " [30.255993 ]\n",
            " [19.231747 ]\n",
            " [17.671114 ]\n",
            " [18.924547 ]\n",
            " [19.991865 ]\n",
            " [30.161041 ]\n",
            " [30.813557 ]\n",
            " [29.8812   ]\n",
            " [24.44552  ]\n",
            " [25.8435   ]\n",
            " [17.632317 ]\n",
            " [25.773966 ]\n",
            " [26.401392 ]\n",
            " [22.7577   ]\n",
            " [16.631071 ]\n",
            " [15.320097 ]\n",
            " [17.251516 ]\n",
            " [18.717468 ]\n",
            " [30.702051 ]\n",
            " [28.794579 ]\n",
            " [31.512602 ]\n",
            " [29.184595 ]\n",
            " [31.42755  ]\n",
            " [18.234518 ]\n",
            " [17.372576 ]\n",
            " [16.777456 ]\n",
            " [15.57055  ]\n",
            " [20.0195   ]\n",
            " [20.819828 ]\n",
            " [19.770771 ]\n",
            " [19.566992 ]\n",
            " [15.962923 ]\n",
            " [17.148685 ]\n",
            " [16.509672 ]\n",
            " [15.214042 ]\n",
            " [31.106302 ]\n",
            " [25.491447 ]\n",
            " [30.164513 ]\n",
            " [25.8255   ]\n",
            " [28.815193 ]\n",
            " [30.110725 ]\n",
            " [30.493782 ]\n",
            " [29.78745  ]\n",
            " [26.613625 ]\n",
            " [29.323992 ]\n",
            " [30.471313 ]\n",
            " [30.593046 ]\n",
            " [30.172375 ]\n",
            " [30.97691  ]\n",
            " [31.636955 ]\n",
            " [31.463945 ]\n",
            " [20.47534  ]\n",
            " [18.687716 ]\n",
            " [19.867884 ]\n",
            " [21.211475 ]\n",
            " [23.08076  ]\n",
            " [22.671175 ]\n",
            " [26.264263 ]\n",
            " [21.083746 ]\n",
            " [21.107416 ]\n",
            " [21.238863 ]\n",
            " [22.348633 ]\n",
            " [21.298248 ]\n",
            " [21.273447 ]\n",
            " [21.06444  ]\n",
            " [25.354843 ]\n",
            " [21.320381 ]\n",
            " [17.095728 ]\n",
            " [29.042887 ]\n",
            " [28.69148  ]\n",
            " [30.749266 ]\n",
            " [28.583588 ]\n",
            " [29.043245 ]\n",
            " [27.290752 ]\n",
            " [25.459028 ]\n",
            " [30.274998 ]\n",
            " [28.277378 ]\n",
            " [26.889242 ]\n",
            " [29.839708 ]\n",
            " [26.695978 ]\n",
            " [31.071987 ]\n",
            " [30.282354 ]\n",
            " [23.079056 ]\n",
            " [23.503378 ]\n",
            " [26.27354  ]\n",
            " [21.488533 ]\n",
            " [22.560387 ]\n",
            " [18.691946 ]\n",
            " [18.843388 ]\n",
            " [16.767714 ]\n",
            " [18.67517  ]\n",
            " [16.57765  ]\n",
            " [16.848375 ]\n",
            " [20.624022 ]\n",
            " [17.487951 ]\n",
            " [31.632875 ]\n",
            " [31.357483 ]\n",
            " [31.197542 ]\n",
            " [26.835478 ]\n",
            " [22.282139 ]\n",
            " [16.908236 ]\n",
            " [25.995039 ]\n",
            " [20.439165 ]\n",
            " [28.472193 ]\n",
            " [29.086973 ]\n",
            " [32.035866 ]\n",
            " [30.54181  ]\n",
            " [26.872808 ]\n",
            " [27.338337 ]\n",
            " [27.167496 ]\n",
            " [26.827993 ]\n",
            " [31.252008 ]\n",
            " [32.093918 ]\n",
            " [30.034859 ]\n",
            " [31.83616  ]\n",
            " [27.37719  ]\n",
            " [26.9809   ]\n",
            " [26.555288 ]\n",
            " [21.695177 ]\n",
            " [31.472178 ]\n",
            " [28.686821 ]\n",
            " [29.183271 ]\n",
            " [30.611757 ]\n",
            " [30.452406 ]\n",
            " [31.71263  ]\n",
            " [27.39237  ]\n",
            " [32.02773  ]\n",
            " [31.014517 ]\n",
            " [30.215677 ]\n",
            " [26.784918 ]\n",
            " [24.98697  ]\n",
            " [32.103504 ]\n",
            " [35.219597 ]\n",
            " [31.358343 ]\n",
            " [32.000866 ]\n",
            " [28.934101 ]\n",
            " [32.548985 ]\n",
            " [29.770967 ]\n",
            " [26.439404 ]\n",
            " [30.50491  ]\n",
            " [28.606531 ]\n",
            " [27.507275 ]\n",
            " [27.641174 ]\n",
            " [27.437279 ]\n",
            " [28.517406 ]\n",
            " [33.33755  ]\n",
            " [31.779516 ]\n",
            " [33.237755 ]\n",
            " [32.144806 ]\n",
            " [33.171978 ]\n",
            " [31.96548  ]\n",
            " [32.432796 ]\n",
            " [29.059345 ]\n",
            " [30.578735 ]\n",
            " [29.902456 ]\n",
            " [30.95269  ]\n",
            " [32.436882 ]\n",
            " [31.01918  ]\n",
            " [30.815601 ]\n",
            " [30.772593 ]\n",
            " [29.251137 ]\n",
            " [26.459171 ]\n",
            " [25.952703 ]\n",
            " [28.35713  ]\n",
            " [29.537085 ]\n",
            " [22.785936 ]\n",
            " [17.336435 ]\n",
            " [24.038797 ]\n",
            " [20.848803 ]\n",
            " [30.421412 ]\n",
            " [30.032251 ]\n",
            " [31.109833 ]\n",
            " [29.584862 ]\n",
            " [28.934525 ]\n",
            " [28.292223 ]\n",
            " [27.838774 ]\n",
            " [27.64432  ]\n",
            " [32.66148  ]\n",
            " [33.14779  ]\n",
            " [33.288883 ]\n",
            " [29.895168 ]\n",
            " [31.271273 ]\n",
            " [32.361053 ]\n",
            " [31.501026 ]\n",
            " [31.377338 ]\n",
            " [32.667652 ]\n",
            " [32.81929  ]\n",
            " [32.779774 ]\n",
            " [27.343657 ]\n",
            " [22.348833 ]\n",
            " [28.270908 ]\n",
            " [25.973454 ]\n",
            " [29.598457 ]\n",
            " [29.048502 ]\n",
            " [27.080818 ]\n",
            " [27.539387 ]\n",
            " [32.38784  ]\n",
            " [29.1149   ]\n",
            " [29.09457  ]\n",
            " [29.081089 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We would like to see how good these predictions are. We know what the correct MPG is for each car, so we can measure how close the neural network was."
      ],
      "metadata": {
        "id": "bsldUfbGS5R0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Measure RMSE error.  RMSE is common for regression.\n",
        "score = np.sqrt(metrics.mean_squared_error(pred,y))\n",
        "print(\"Final score (RMSE): {}\".format(score))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYY8qU7BS5aq",
        "outputId": "6788ded6-e368-4aa3-8ca9-c8c82b4433dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final score (RMSE): 3.9592444896698\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also print out the first 10 cars, with predictions and actual MPG."
      ],
      "metadata": {
        "id": "iJD8USzaTAy7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample predictions\n",
        "for i in range(10):\n",
        "    print(\"{}. Car name: {}, MPG: {}, predicted MPG: {}\".format(i+1,cars[i],y[i],pred[i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nF465bncTC3N",
        "outputId": "3e5a132b-3792-47b2-f7b3-64dc0292ed32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Car name: chevrolet chevelle malibu, MPG: 18.0, predicted MPG: [15.624652]\n",
            "2. Car name: buick skylark 320, MPG: 15.0, predicted MPG: [16.035051]\n",
            "3. Car name: plymouth satellite, MPG: 18.0, predicted MPG: [17.026726]\n",
            "4. Car name: amc rebel sst, MPG: 16.0, predicted MPG: [17.727373]\n",
            "5. Car name: ford torino, MPG: 17.0, predicted MPG: [16.564383]\n",
            "6. Car name: ford galaxie 500, MPG: 15.0, predicted MPG: [12.594571]\n",
            "7. Car name: chevrolet impala, MPG: 14.0, predicted MPG: [13.293249]\n",
            "8. Car name: plymouth fury iii, MPG: 14.0, predicted MPG: [13.448194]\n",
            "9. Car name: pontiac catalina, MPG: 14.0, predicted MPG: [13.53947]\n",
            "10. Car name: amc ambassador dpl, MPG: 15.0, predicted MPG: [15.335877]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3 Example of Tensorflow classification: Iris"
      ],
      "metadata": {
        "id": "j-F2fEq5TGR3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "This is a very simple example of how to perform the Iris classification using TensorFlow. The iris.csv file is used."
      ],
      "metadata": {
        "id": "xakvNWaTTMm_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "import requests\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "\n",
        "df=pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/CSC219-MachineLearning/labs/data/iris.csv\",na_values=['NA','?'])\n",
        "\n",
        "species = encode_text_index(df,\"species\")\n",
        "\n",
        "x,y = to_xy(df,\"species\")"
      ],
      "metadata": {
        "id": "j-OVrezfTMwY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5-wAGVmTdwJ",
        "outputId": "9fb9006e-de2a-47ff-9b2f-ce86c35d04f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.1, 3.5, 1.4, 0.2],\n",
              "       [4.9, 3. , 1.4, 0.2],\n",
              "       [4.7, 3.2, 1.3, 0.2],\n",
              "       [4.6, 3.1, 1.5, 0.2],\n",
              "       [5. , 3.6, 1.4, 0.2],\n",
              "       [5.4, 3.9, 1.7, 0.4],\n",
              "       [4.6, 3.4, 1.4, 0.3],\n",
              "       [5. , 3.4, 1.5, 0.2],\n",
              "       [4.4, 2.9, 1.4, 0.2],\n",
              "       [4.9, 3.1, 1.5, 0.1],\n",
              "       [5.4, 3.7, 1.5, 0.2],\n",
              "       [4.8, 3.4, 1.6, 0.2],\n",
              "       [4.8, 3. , 1.4, 0.1],\n",
              "       [4.3, 3. , 1.1, 0.1],\n",
              "       [5.8, 4. , 1.2, 0.2],\n",
              "       [5.7, 4.4, 1.5, 0.4],\n",
              "       [5.4, 3.9, 1.3, 0.4],\n",
              "       [5.1, 3.5, 1.4, 0.3],\n",
              "       [5.7, 3.8, 1.7, 0.3],\n",
              "       [5.1, 3.8, 1.5, 0.3],\n",
              "       [5.4, 3.4, 1.7, 0.2],\n",
              "       [5.1, 3.7, 1.5, 0.4],\n",
              "       [4.6, 3.6, 1. , 0.2],\n",
              "       [5.1, 3.3, 1.7, 0.5],\n",
              "       [4.8, 3.4, 1.9, 0.2],\n",
              "       [5. , 3. , 1.6, 0.2],\n",
              "       [5. , 3.4, 1.6, 0.4],\n",
              "       [5.2, 3.5, 1.5, 0.2],\n",
              "       [5.2, 3.4, 1.4, 0.2],\n",
              "       [4.7, 3.2, 1.6, 0.2],\n",
              "       [4.8, 3.1, 1.6, 0.2],\n",
              "       [5.4, 3.4, 1.5, 0.4],\n",
              "       [5.2, 4.1, 1.5, 0.1],\n",
              "       [5.5, 4.2, 1.4, 0.2],\n",
              "       [4.9, 3.1, 1.5, 0.2],\n",
              "       [5. , 3.2, 1.2, 0.2],\n",
              "       [5.5, 3.5, 1.3, 0.2],\n",
              "       [4.9, 3.6, 1.4, 0.1],\n",
              "       [4.4, 3. , 1.3, 0.2],\n",
              "       [5.1, 3.4, 1.5, 0.2],\n",
              "       [5. , 3.5, 1.3, 0.3],\n",
              "       [4.5, 2.3, 1.3, 0.3],\n",
              "       [4.4, 3.2, 1.3, 0.2],\n",
              "       [5. , 3.5, 1.6, 0.6],\n",
              "       [5.1, 3.8, 1.9, 0.4],\n",
              "       [4.8, 3. , 1.4, 0.3],\n",
              "       [5.1, 3.8, 1.6, 0.2],\n",
              "       [4.6, 3.2, 1.4, 0.2],\n",
              "       [5.3, 3.7, 1.5, 0.2],\n",
              "       [5. , 3.3, 1.4, 0.2],\n",
              "       [7. , 3.2, 4.7, 1.4],\n",
              "       [6.4, 3.2, 4.5, 1.5],\n",
              "       [6.9, 3.1, 4.9, 1.5],\n",
              "       [5.5, 2.3, 4. , 1.3],\n",
              "       [6.5, 2.8, 4.6, 1.5],\n",
              "       [5.7, 2.8, 4.5, 1.3],\n",
              "       [6.3, 3.3, 4.7, 1.6],\n",
              "       [4.9, 2.4, 3.3, 1. ],\n",
              "       [6.6, 2.9, 4.6, 1.3],\n",
              "       [5.2, 2.7, 3.9, 1.4],\n",
              "       [5. , 2. , 3.5, 1. ],\n",
              "       [5.9, 3. , 4.2, 1.5],\n",
              "       [6. , 2.2, 4. , 1. ],\n",
              "       [6.1, 2.9, 4.7, 1.4],\n",
              "       [5.6, 2.9, 3.6, 1.3],\n",
              "       [6.7, 3.1, 4.4, 1.4],\n",
              "       [5.6, 3. , 4.5, 1.5],\n",
              "       [5.8, 2.7, 4.1, 1. ],\n",
              "       [6.2, 2.2, 4.5, 1.5],\n",
              "       [5.6, 2.5, 3.9, 1.1],\n",
              "       [5.9, 3.2, 4.8, 1.8],\n",
              "       [6.1, 2.8, 4. , 1.3],\n",
              "       [6.3, 2.5, 4.9, 1.5],\n",
              "       [6.1, 2.8, 4.7, 1.2],\n",
              "       [6.4, 2.9, 4.3, 1.3],\n",
              "       [6.6, 3. , 4.4, 1.4],\n",
              "       [6.8, 2.8, 4.8, 1.4],\n",
              "       [6.7, 3. , 5. , 1.7],\n",
              "       [6. , 2.9, 4.5, 1.5],\n",
              "       [5.7, 2.6, 3.5, 1. ],\n",
              "       [5.5, 2.4, 3.8, 1.1],\n",
              "       [5.5, 2.4, 3.7, 1. ],\n",
              "       [5.8, 2.7, 3.9, 1.2],\n",
              "       [6. , 2.7, 5.1, 1.6],\n",
              "       [5.4, 3. , 4.5, 1.5],\n",
              "       [6. , 3.4, 4.5, 1.6],\n",
              "       [6.7, 3.1, 4.7, 1.5],\n",
              "       [6.3, 2.3, 4.4, 1.3],\n",
              "       [5.6, 3. , 4.1, 1.3],\n",
              "       [5.5, 2.5, 4. , 1.3],\n",
              "       [5.5, 2.6, 4.4, 1.2],\n",
              "       [6.1, 3. , 4.6, 1.4],\n",
              "       [5.8, 2.6, 4. , 1.2],\n",
              "       [5. , 2.3, 3.3, 1. ],\n",
              "       [5.6, 2.7, 4.2, 1.3],\n",
              "       [5.7, 3. , 4.2, 1.2],\n",
              "       [5.7, 2.9, 4.2, 1.3],\n",
              "       [6.2, 2.9, 4.3, 1.3],\n",
              "       [5.1, 2.5, 3. , 1.1],\n",
              "       [5.7, 2.8, 4.1, 1.3],\n",
              "       [6.3, 3.3, 6. , 2.5],\n",
              "       [5.8, 2.7, 5.1, 1.9],\n",
              "       [7.1, 3. , 5.9, 2.1],\n",
              "       [6.3, 2.9, 5.6, 1.8],\n",
              "       [6.5, 3. , 5.8, 2.2],\n",
              "       [7.6, 3. , 6.6, 2.1],\n",
              "       [4.9, 2.5, 4.5, 1.7],\n",
              "       [7.3, 2.9, 6.3, 1.8],\n",
              "       [6.7, 2.5, 5.8, 1.8],\n",
              "       [7.2, 3.6, 6.1, 2.5],\n",
              "       [6.5, 3.2, 5.1, 2. ],\n",
              "       [6.4, 2.7, 5.3, 1.9],\n",
              "       [6.8, 3. , 5.5, 2.1],\n",
              "       [5.7, 2.5, 5. , 2. ],\n",
              "       [5.8, 2.8, 5.1, 2.4],\n",
              "       [6.4, 3.2, 5.3, 2.3],\n",
              "       [6.5, 3. , 5.5, 1.8],\n",
              "       [7.7, 3.8, 6.7, 2.2],\n",
              "       [7.7, 2.6, 6.9, 2.3],\n",
              "       [6. , 2.2, 5. , 1.5],\n",
              "       [6.9, 3.2, 5.7, 2.3],\n",
              "       [5.6, 2.8, 4.9, 2. ],\n",
              "       [7.7, 2.8, 6.7, 2. ],\n",
              "       [6.3, 2.7, 4.9, 1.8],\n",
              "       [6.7, 3.3, 5.7, 2.1],\n",
              "       [7.2, 3.2, 6. , 1.8],\n",
              "       [6.2, 2.8, 4.8, 1.8],\n",
              "       [6.1, 3. , 4.9, 1.8],\n",
              "       [6.4, 2.8, 5.6, 2.1],\n",
              "       [7.2, 3. , 5.8, 1.6],\n",
              "       [7.4, 2.8, 6.1, 1.9],\n",
              "       [7.9, 3.8, 6.4, 2. ],\n",
              "       [6.4, 2.8, 5.6, 2.2],\n",
              "       [6.3, 2.8, 5.1, 1.5],\n",
              "       [6.1, 2.6, 5.6, 1.4],\n",
              "       [7.7, 3. , 6.1, 2.3],\n",
              "       [6.3, 3.4, 5.6, 2.4],\n",
              "       [6.4, 3.1, 5.5, 1.8],\n",
              "       [6. , 3. , 4.8, 1.8],\n",
              "       [6.9, 3.1, 5.4, 2.1],\n",
              "       [6.7, 3.1, 5.6, 2.4],\n",
              "       [6.9, 3.1, 5.1, 2.3],\n",
              "       [5.8, 2.7, 5.1, 1.9],\n",
              "       [6.8, 3.2, 5.9, 2.3],\n",
              "       [6.7, 3.3, 5.7, 2.5],\n",
              "       [6.7, 3. , 5.2, 2.3],\n",
              "       [6.3, 2.5, 5. , 1.9],\n",
              "       [6.5, 3. , 5.2, 2. ],\n",
              "       [6.2, 3.4, 5.4, 2.3],\n",
              "       [5.9, 3. , 5.1, 1.8]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZLGcrjKTg8s",
        "outputId": "a5dee221-cf3b-4b1f-a696-8254840555f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y  #  This is one-hot encoding.  Only one value is 1.0 (hot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVxOLG-qTjYn",
        "outputId": "d68a5501-76d8-47d4-9fa2-239cd39c57c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVh3u3hRTmtG",
        "outputId": "d9809151-8eb7-4f61-d643-507a11643099"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(50, input_dim=x.shape[1], activation='relu')) # Hidden 1\n",
        "model.add(Dense(25, activation='relu')) # Hidden 2\n",
        "model.add(Dense(y.shape[1], activation='softmax')) # Output\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "model.fit(x,y,verbose=2,epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Z6hRX24TrXI",
        "outputId": "49ee8c78-eea3-42eb-aefb-a572c2b01912"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "5/5 - 2s - loss: 1.1507 - 2s/epoch - 370ms/step\n",
            "Epoch 2/100\n",
            "5/5 - 0s - loss: 0.9981 - 9ms/epoch - 2ms/step\n",
            "Epoch 3/100\n",
            "5/5 - 0s - loss: 0.9224 - 8ms/epoch - 2ms/step\n",
            "Epoch 4/100\n",
            "5/5 - 0s - loss: 0.8531 - 11ms/epoch - 2ms/step\n",
            "Epoch 5/100\n",
            "5/5 - 0s - loss: 0.7877 - 10ms/epoch - 2ms/step\n",
            "Epoch 6/100\n",
            "5/5 - 0s - loss: 0.7321 - 8ms/epoch - 2ms/step\n",
            "Epoch 7/100\n",
            "5/5 - 0s - loss: 0.6841 - 8ms/epoch - 2ms/step\n",
            "Epoch 8/100\n",
            "5/5 - 0s - loss: 0.6456 - 8ms/epoch - 2ms/step\n",
            "Epoch 9/100\n",
            "5/5 - 0s - loss: 0.6094 - 8ms/epoch - 2ms/step\n",
            "Epoch 10/100\n",
            "5/5 - 0s - loss: 0.5814 - 8ms/epoch - 2ms/step\n",
            "Epoch 11/100\n",
            "5/5 - 0s - loss: 0.5531 - 8ms/epoch - 2ms/step\n",
            "Epoch 12/100\n",
            "5/5 - 0s - loss: 0.5289 - 10ms/epoch - 2ms/step\n",
            "Epoch 13/100\n",
            "5/5 - 0s - loss: 0.5089 - 9ms/epoch - 2ms/step\n",
            "Epoch 14/100\n",
            "5/5 - 0s - loss: 0.4923 - 10ms/epoch - 2ms/step\n",
            "Epoch 15/100\n",
            "5/5 - 0s - loss: 0.4755 - 10ms/epoch - 2ms/step\n",
            "Epoch 16/100\n",
            "5/5 - 0s - loss: 0.4649 - 9ms/epoch - 2ms/step\n",
            "Epoch 17/100\n",
            "5/5 - 0s - loss: 0.4562 - 10ms/epoch - 2ms/step\n",
            "Epoch 18/100\n",
            "5/5 - 0s - loss: 0.4386 - 12ms/epoch - 2ms/step\n",
            "Epoch 19/100\n",
            "5/5 - 0s - loss: 0.4284 - 9ms/epoch - 2ms/step\n",
            "Epoch 20/100\n",
            "5/5 - 0s - loss: 0.4197 - 13ms/epoch - 3ms/step\n",
            "Epoch 21/100\n",
            "5/5 - 0s - loss: 0.4093 - 11ms/epoch - 2ms/step\n",
            "Epoch 22/100\n",
            "5/5 - 0s - loss: 0.4018 - 9ms/epoch - 2ms/step\n",
            "Epoch 23/100\n",
            "5/5 - 0s - loss: 0.3955 - 10ms/epoch - 2ms/step\n",
            "Epoch 24/100\n",
            "5/5 - 0s - loss: 0.3839 - 10ms/epoch - 2ms/step\n",
            "Epoch 25/100\n",
            "5/5 - 0s - loss: 0.3766 - 11ms/epoch - 2ms/step\n",
            "Epoch 26/100\n",
            "5/5 - 0s - loss: 0.3698 - 10ms/epoch - 2ms/step\n",
            "Epoch 27/100\n",
            "5/5 - 0s - loss: 0.3614 - 8ms/epoch - 2ms/step\n",
            "Epoch 28/100\n",
            "5/5 - 0s - loss: 0.3543 - 9ms/epoch - 2ms/step\n",
            "Epoch 29/100\n",
            "5/5 - 0s - loss: 0.3468 - 8ms/epoch - 2ms/step\n",
            "Epoch 30/100\n",
            "5/5 - 0s - loss: 0.3401 - 8ms/epoch - 2ms/step\n",
            "Epoch 31/100\n",
            "5/5 - 0s - loss: 0.3330 - 8ms/epoch - 2ms/step\n",
            "Epoch 32/100\n",
            "5/5 - 0s - loss: 0.3267 - 8ms/epoch - 2ms/step\n",
            "Epoch 33/100\n",
            "5/5 - 0s - loss: 0.3197 - 9ms/epoch - 2ms/step\n",
            "Epoch 34/100\n",
            "5/5 - 0s - loss: 0.3129 - 9ms/epoch - 2ms/step\n",
            "Epoch 35/100\n",
            "5/5 - 0s - loss: 0.3101 - 8ms/epoch - 2ms/step\n",
            "Epoch 36/100\n",
            "5/5 - 0s - loss: 0.3032 - 8ms/epoch - 2ms/step\n",
            "Epoch 37/100\n",
            "5/5 - 0s - loss: 0.2928 - 10ms/epoch - 2ms/step\n",
            "Epoch 38/100\n",
            "5/5 - 0s - loss: 0.2874 - 10ms/epoch - 2ms/step\n",
            "Epoch 39/100\n",
            "5/5 - 0s - loss: 0.2807 - 9ms/epoch - 2ms/step\n",
            "Epoch 40/100\n",
            "5/5 - 0s - loss: 0.2740 - 10ms/epoch - 2ms/step\n",
            "Epoch 41/100\n",
            "5/5 - 0s - loss: 0.2715 - 10ms/epoch - 2ms/step\n",
            "Epoch 42/100\n",
            "5/5 - 0s - loss: 0.2613 - 11ms/epoch - 2ms/step\n",
            "Epoch 43/100\n",
            "5/5 - 0s - loss: 0.2554 - 14ms/epoch - 3ms/step\n",
            "Epoch 44/100\n",
            "5/5 - 0s - loss: 0.2498 - 11ms/epoch - 2ms/step\n",
            "Epoch 45/100\n",
            "5/5 - 0s - loss: 0.2453 - 9ms/epoch - 2ms/step\n",
            "Epoch 46/100\n",
            "5/5 - 0s - loss: 0.2418 - 10ms/epoch - 2ms/step\n",
            "Epoch 47/100\n",
            "5/5 - 0s - loss: 0.2332 - 9ms/epoch - 2ms/step\n",
            "Epoch 48/100\n",
            "5/5 - 0s - loss: 0.2279 - 11ms/epoch - 2ms/step\n",
            "Epoch 49/100\n",
            "5/5 - 0s - loss: 0.2226 - 9ms/epoch - 2ms/step\n",
            "Epoch 50/100\n",
            "5/5 - 0s - loss: 0.2194 - 9ms/epoch - 2ms/step\n",
            "Epoch 51/100\n",
            "5/5 - 0s - loss: 0.2118 - 9ms/epoch - 2ms/step\n",
            "Epoch 52/100\n",
            "5/5 - 0s - loss: 0.2099 - 8ms/epoch - 2ms/step\n",
            "Epoch 53/100\n",
            "5/5 - 0s - loss: 0.2038 - 9ms/epoch - 2ms/step\n",
            "Epoch 54/100\n",
            "5/5 - 0s - loss: 0.1988 - 9ms/epoch - 2ms/step\n",
            "Epoch 55/100\n",
            "5/5 - 0s - loss: 0.1938 - 11ms/epoch - 2ms/step\n",
            "Epoch 56/100\n",
            "5/5 - 0s - loss: 0.1899 - 11ms/epoch - 2ms/step\n",
            "Epoch 57/100\n",
            "5/5 - 0s - loss: 0.1855 - 9ms/epoch - 2ms/step\n",
            "Epoch 58/100\n",
            "5/5 - 0s - loss: 0.1842 - 10ms/epoch - 2ms/step\n",
            "Epoch 59/100\n",
            "5/5 - 0s - loss: 0.1852 - 8ms/epoch - 2ms/step\n",
            "Epoch 60/100\n",
            "5/5 - 0s - loss: 0.1784 - 8ms/epoch - 2ms/step\n",
            "Epoch 61/100\n",
            "5/5 - 0s - loss: 0.1701 - 8ms/epoch - 2ms/step\n",
            "Epoch 62/100\n",
            "5/5 - 0s - loss: 0.1651 - 8ms/epoch - 2ms/step\n",
            "Epoch 63/100\n",
            "5/5 - 0s - loss: 0.1635 - 8ms/epoch - 2ms/step\n",
            "Epoch 64/100\n",
            "5/5 - 0s - loss: 0.1583 - 8ms/epoch - 2ms/step\n",
            "Epoch 65/100\n",
            "5/5 - 0s - loss: 0.1555 - 10ms/epoch - 2ms/step\n",
            "Epoch 66/100\n",
            "5/5 - 0s - loss: 0.1554 - 9ms/epoch - 2ms/step\n",
            "Epoch 67/100\n",
            "5/5 - 0s - loss: 0.1488 - 11ms/epoch - 2ms/step\n",
            "Epoch 68/100\n",
            "5/5 - 0s - loss: 0.1481 - 10ms/epoch - 2ms/step\n",
            "Epoch 69/100\n",
            "5/5 - 0s - loss: 0.1419 - 9ms/epoch - 2ms/step\n",
            "Epoch 70/100\n",
            "5/5 - 0s - loss: 0.1419 - 8ms/epoch - 2ms/step\n",
            "Epoch 71/100\n",
            "5/5 - 0s - loss: 0.1386 - 12ms/epoch - 2ms/step\n",
            "Epoch 72/100\n",
            "5/5 - 0s - loss: 0.1342 - 13ms/epoch - 3ms/step\n",
            "Epoch 73/100\n",
            "5/5 - 0s - loss: 0.1316 - 12ms/epoch - 2ms/step\n",
            "Epoch 74/100\n",
            "5/5 - 0s - loss: 0.1298 - 10ms/epoch - 2ms/step\n",
            "Epoch 75/100\n",
            "5/5 - 0s - loss: 0.1268 - 11ms/epoch - 2ms/step\n",
            "Epoch 76/100\n",
            "5/5 - 0s - loss: 0.1247 - 10ms/epoch - 2ms/step\n",
            "Epoch 77/100\n",
            "5/5 - 0s - loss: 0.1226 - 11ms/epoch - 2ms/step\n",
            "Epoch 78/100\n",
            "5/5 - 0s - loss: 0.1213 - 11ms/epoch - 2ms/step\n",
            "Epoch 79/100\n",
            "5/5 - 0s - loss: 0.1293 - 9ms/epoch - 2ms/step\n",
            "Epoch 80/100\n",
            "5/5 - 0s - loss: 0.1178 - 10ms/epoch - 2ms/step\n",
            "Epoch 81/100\n",
            "5/5 - 0s - loss: 0.1210 - 9ms/epoch - 2ms/step\n",
            "Epoch 82/100\n",
            "5/5 - 0s - loss: 0.1132 - 8ms/epoch - 2ms/step\n",
            "Epoch 83/100\n",
            "5/5 - 0s - loss: 0.1140 - 9ms/epoch - 2ms/step\n",
            "Epoch 84/100\n",
            "5/5 - 0s - loss: 0.1108 - 14ms/epoch - 3ms/step\n",
            "Epoch 85/100\n",
            "5/5 - 0s - loss: 0.1121 - 12ms/epoch - 2ms/step\n",
            "Epoch 86/100\n",
            "5/5 - 0s - loss: 0.1072 - 8ms/epoch - 2ms/step\n",
            "Epoch 87/100\n",
            "5/5 - 0s - loss: 0.1081 - 8ms/epoch - 2ms/step\n",
            "Epoch 88/100\n",
            "5/5 - 0s - loss: 0.1063 - 14ms/epoch - 3ms/step\n",
            "Epoch 89/100\n",
            "5/5 - 0s - loss: 0.1067 - 10ms/epoch - 2ms/step\n",
            "Epoch 90/100\n",
            "5/5 - 0s - loss: 0.1006 - 10ms/epoch - 2ms/step\n",
            "Epoch 91/100\n",
            "5/5 - 0s - loss: 0.1031 - 9ms/epoch - 2ms/step\n",
            "Epoch 92/100\n",
            "5/5 - 0s - loss: 0.0991 - 9ms/epoch - 2ms/step\n",
            "Epoch 93/100\n",
            "5/5 - 0s - loss: 0.1001 - 9ms/epoch - 2ms/step\n",
            "Epoch 94/100\n",
            "5/5 - 0s - loss: 0.0998 - 8ms/epoch - 2ms/step\n",
            "Epoch 95/100\n",
            "5/5 - 0s - loss: 0.0987 - 8ms/epoch - 2ms/step\n",
            "Epoch 96/100\n",
            "5/5 - 0s - loss: 0.0972 - 9ms/epoch - 2ms/step\n",
            "Epoch 97/100\n",
            "5/5 - 0s - loss: 0.0944 - 10ms/epoch - 2ms/step\n",
            "Epoch 98/100\n",
            "5/5 - 0s - loss: 0.0948 - 8ms/epoch - 2ms/step\n",
            "Epoch 99/100\n",
            "5/5 - 0s - loss: 0.0930 - 10ms/epoch - 2ms/step\n",
            "Epoch 100/100\n",
            "5/5 - 0s - loss: 0.0923 - 11ms/epoch - 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7fd3326bf0d0>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print out number of species found:\n",
        "print(species)"
      ],
      "metadata": {
        "id": "n1Gxfu_zTul_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "257672f7-9ea5-4f22-f376-916498f3c4d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Iris-setosa' 'Iris-versicolor' 'Iris-virginica']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that you have a neural network trained, we would like to be able to use it. There were 3 types of iris (Iris-setosa, Iris-versicolor, and Iris-virginica)."
      ],
      "metadata": {
        "id": "w1vuXGDhTxAq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict(x)\n",
        "pred.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nd3sBM-fTylE",
        "outputId": "c77f5c43-5504-4321-a369-2f8816bf1c6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzBQ84koT1M7",
        "outputId": "89d9968d-baf0-4f5a-c2dd-f0d945af6acb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.97788072e-01, 2.21190299e-03, 4.45829151e-09],\n",
              "       [9.95578945e-01, 4.42100735e-03, 2.47375329e-08],\n",
              "       [9.96394813e-01, 3.60524911e-03, 1.88487608e-08],\n",
              "       [9.93545234e-01, 6.45466708e-03, 6.09107857e-08],\n",
              "       [9.97823358e-01, 2.17669317e-03, 4.54204141e-09],\n",
              "       [9.97098446e-01, 2.90157506e-03, 4.70305528e-09],\n",
              "       [9.95499551e-01, 4.50059772e-03, 2.99236937e-08],\n",
              "       [9.96895134e-01, 3.10490723e-03, 9.72257741e-09],\n",
              "       [9.92188394e-01, 7.81141128e-03, 1.18226474e-07],\n",
              "       [9.96010363e-01, 3.98970861e-03, 1.82260607e-08],\n",
              "       [9.98367608e-01, 1.63238018e-03, 1.72214665e-09],\n",
              "       [9.95293021e-01, 4.70701652e-03, 2.40894060e-08],\n",
              "       [9.95935798e-01, 4.06413060e-03, 2.19911875e-08],\n",
              "       [9.96085942e-01, 3.91401676e-03, 3.27211858e-08],\n",
              "       [9.99406576e-01, 5.93426405e-04, 1.35618072e-10],\n",
              "       [9.99112368e-01, 8.87518981e-04, 3.27470995e-10],\n",
              "       [9.98601258e-01, 1.39873882e-03, 1.29460420e-09],\n",
              "       [9.97366428e-01, 2.63348292e-03, 6.51234267e-09],\n",
              "       [9.98024046e-01, 1.97587465e-03, 1.77462733e-09],\n",
              "       [9.97734785e-01, 2.26519816e-03, 4.26637703e-09],\n",
              "       [9.96466100e-01, 3.53396311e-03, 7.61395480e-09],\n",
              "       [9.96867776e-01, 3.13221151e-03, 8.36314307e-09],\n",
              "       [9.98236895e-01, 1.76314323e-03, 4.13510470e-09],\n",
              "       [9.88031149e-01, 1.19686956e-02, 1.06956847e-07],\n",
              "       [9.88670945e-01, 1.13289915e-02, 1.02082375e-07],\n",
              "       [9.93102729e-01, 6.89719757e-03, 4.58290685e-08],\n",
              "       [9.93750811e-01, 6.24909531e-03, 3.53773721e-08],\n",
              "       [9.97635961e-01, 2.36407993e-03, 4.59726968e-09],\n",
              "       [9.97752368e-01, 2.24767835e-03, 4.37605818e-09],\n",
              "       [9.93332148e-01, 6.66777184e-03, 5.38849250e-08],\n",
              "       [9.92902398e-01, 7.09767547e-03, 5.66804879e-08],\n",
              "       [9.96617734e-01, 3.38217034e-03, 8.27063751e-09],\n",
              "       [9.98914599e-01, 1.08537544e-03, 7.62762409e-10],\n",
              "       [9.99211967e-01, 7.88038771e-04, 3.09649861e-10],\n",
              "       [9.95103776e-01, 4.89609875e-03, 2.76039085e-08],\n",
              "       [9.97539103e-01, 2.46101175e-03, 6.67826727e-09],\n",
              "       [9.98602211e-01, 1.39774475e-03, 1.22880228e-09],\n",
              "       [9.98010457e-01, 1.98942912e-03, 4.01145295e-09],\n",
              "       [9.94324565e-01, 5.67529723e-03, 6.48405631e-08],\n",
              "       [9.97144103e-01, 2.85592023e-03, 7.54411289e-09],\n",
              "       [9.97536004e-01, 2.46401131e-03, 6.31559338e-09],\n",
              "       [9.81930852e-01, 1.80683695e-02, 6.77152059e-07],\n",
              "       [9.95356262e-01, 4.64382069e-03, 4.04569249e-08],\n",
              "       [9.90605712e-01, 9.39408410e-03, 7.61316699e-08],\n",
              "       [9.92439687e-01, 7.56019121e-03, 3.36618946e-08],\n",
              "       [9.94050086e-01, 5.94990142e-03, 4.88140053e-08],\n",
              "       [9.97787237e-01, 2.21279054e-03, 3.88550347e-09],\n",
              "       [9.95438874e-01, 4.56116861e-03, 3.23374643e-08],\n",
              "       [9.98223424e-01, 1.77646405e-03, 2.22192287e-09],\n",
              "       [9.97056901e-01, 2.94312346e-03, 9.22304366e-09],\n",
              "       [1.19800132e-03, 9.90270257e-01, 8.53183586e-03],\n",
              "       [1.63338240e-03, 9.72746491e-01, 2.56200861e-02],\n",
              "       [8.66391929e-04, 9.50838387e-01, 4.82951440e-02],\n",
              "       [2.65484559e-03, 8.41282547e-01, 1.56062648e-01],\n",
              "       [1.15801976e-03, 9.09068465e-01, 8.97734836e-02],\n",
              "       [1.79543195e-03, 8.37749481e-01, 1.60455167e-01],\n",
              "       [1.27848214e-03, 9.18950260e-01, 7.97712430e-02],\n",
              "       [1.50765423e-02, 9.72414553e-01, 1.25089455e-02],\n",
              "       [1.41078222e-03, 9.75584745e-01, 2.30043046e-02],\n",
              "       [3.71461804e-03, 8.84643972e-01, 1.11641400e-01],\n",
              "       [6.36035157e-03, 9.42392945e-01, 5.12467399e-02],\n",
              "       [2.39981757e-03, 9.51177955e-01, 4.64222729e-02],\n",
              "       [3.22233629e-03, 9.77272809e-01, 1.95047595e-02],\n",
              "       [1.24427397e-03, 8.42062473e-01, 1.56693280e-01],\n",
              "       [1.03115765e-02, 9.82427001e-01, 7.26146810e-03],\n",
              "       [1.91761611e-03, 9.90433395e-01, 7.64880935e-03],\n",
              "       [1.57150044e-03, 7.48624980e-01, 2.49803573e-01],\n",
              "       [3.97687359e-03, 9.84744370e-01, 1.12787206e-02],\n",
              "       [7.04894541e-04, 5.55503190e-01, 4.43791926e-01],\n",
              "       [3.98860592e-03, 9.74339187e-01, 2.16721129e-02],\n",
              "       [5.83529647e-04, 4.70369995e-01, 5.29046416e-01],\n",
              "       [3.45259742e-03, 9.85954404e-01, 1.05931163e-02],\n",
              "       [4.04373131e-04, 4.40107852e-01, 5.59487820e-01],\n",
              "       [1.46944122e-03, 9.06273127e-01, 9.22574997e-02],\n",
              "       [2.11722124e-03, 9.86301422e-01, 1.15813520e-02],\n",
              "       [1.72670744e-03, 9.85945225e-01, 1.23281647e-02],\n",
              "       [9.36139782e-04, 9.36318815e-01, 6.27450645e-02],\n",
              "       [5.37517015e-04, 7.12003708e-01, 2.87458867e-01],\n",
              "       [1.49512582e-03, 8.54717195e-01, 1.43787697e-01],\n",
              "       [2.21015327e-02, 9.74479318e-01, 3.41910031e-03],\n",
              "       [4.38945647e-03, 9.70768273e-01, 2.48422232e-02],\n",
              "       [6.56150095e-03, 9.80994105e-01, 1.24444654e-02],\n",
              "       [4.17823996e-03, 9.83389616e-01, 1.24320509e-02],\n",
              "       [1.39166383e-04, 1.63953707e-01, 8.35907102e-01],\n",
              "       [1.46119588e-03, 6.46754742e-01, 3.51784140e-01],\n",
              "       [1.84193614e-03, 9.40748334e-01, 5.74097447e-02],\n",
              "       [1.14872889e-03, 9.62780714e-01, 3.60704437e-02],\n",
              "       [1.40621315e-03, 8.85026217e-01, 1.13567457e-01],\n",
              "       [3.49087501e-03, 9.69226241e-01, 2.72828750e-02],\n",
              "       [3.06024798e-03, 9.03536797e-01, 9.34029892e-02],\n",
              "       [2.03273608e-03, 8.04267228e-01, 1.93700075e-01],\n",
              "       [1.54185679e-03, 9.13132370e-01, 8.53259042e-02],\n",
              "       [3.26240924e-03, 9.73665833e-01, 2.30718367e-02],\n",
              "       [1.36249624e-02, 9.73430455e-01, 1.29445894e-02],\n",
              "       [2.61208485e-03, 9.06953633e-01, 9.04341787e-02],\n",
              "       [3.33885918e-03, 9.76040125e-01, 2.06210464e-02],\n",
              "       [2.84719258e-03, 9.55565155e-01, 4.15876359e-02],\n",
              "       [2.20097974e-03, 9.79125500e-01, 1.86734237e-02],\n",
              "       [4.29864936e-02, 9.52613294e-01, 4.40020533e-03],\n",
              "       [3.04334005e-03, 9.59333301e-01, 3.76232564e-02],\n",
              "       [1.27659803e-06, 4.54122340e-03, 9.95457530e-01],\n",
              "       [2.29475445e-05, 3.04453336e-02, 9.69531775e-01],\n",
              "       [6.26596784e-06, 3.00266203e-02, 9.69967067e-01],\n",
              "       [1.73961653e-05, 3.95722762e-02, 9.60410297e-01],\n",
              "       [2.47989647e-06, 8.65960307e-03, 9.91337836e-01],\n",
              "       [6.49778201e-07, 7.25440914e-03, 9.92744863e-01],\n",
              "       [9.90672997e-05, 4.92665060e-02, 9.50634420e-01],\n",
              "       [4.39923497e-06, 2.87064854e-02, 9.71289098e-01],\n",
              "       [4.57657507e-06, 1.65659674e-02, 9.83429372e-01],\n",
              "       [2.68011286e-06, 1.69437230e-02, 9.83053625e-01],\n",
              "       [2.11120598e-04, 3.23657930e-01, 6.76130950e-01],\n",
              "       [2.88094561e-05, 5.79749085e-02, 9.41996276e-01],\n",
              "       [2.33571482e-05, 6.77224994e-02, 9.32254076e-01],\n",
              "       [1.29177160e-05, 1.59904715e-02, 9.83996511e-01],\n",
              "       [7.33448269e-06, 1.08697265e-02, 9.89122868e-01],\n",
              "       [1.94569402e-05, 4.23986092e-02, 9.57581878e-01],\n",
              "       [5.50600707e-05, 1.17965259e-01, 8.81979644e-01],\n",
              "       [3.41473219e-06, 3.59143317e-02, 9.64082241e-01],\n",
              "       [1.11740697e-07, 1.70828821e-03, 9.98291492e-01],\n",
              "       [8.00043344e-05, 9.56453979e-02, 9.04274583e-01],\n",
              "       [7.69788585e-06, 2.98381411e-02, 9.70154166e-01],\n",
              "       [3.37201382e-05, 3.51620466e-02, 9.64804173e-01],\n",
              "       [4.72484686e-07, 5.95606072e-03, 9.94043410e-01],\n",
              "       [2.18989560e-04, 2.69155741e-01, 7.30625212e-01],\n",
              "       [1.90589381e-05, 5.82834035e-02, 9.41697538e-01],\n",
              "       [3.66645982e-05, 1.54552072e-01, 8.45411301e-01],\n",
              "       [3.51852388e-04, 3.64789963e-01, 6.34858251e-01],\n",
              "       [3.42638465e-04, 3.51906031e-01, 6.47751212e-01],\n",
              "       [3.88112630e-06, 1.11754593e-02, 9.88820732e-01],\n",
              "       [1.08626664e-04, 3.55334133e-01, 6.44557357e-01],\n",
              "       [6.22488960e-06, 3.82583588e-02, 9.61735308e-01],\n",
              "       [4.42265773e-05, 3.28163862e-01, 6.71791852e-01],\n",
              "       [3.14977478e-06, 9.10377223e-03, 9.90892947e-01],\n",
              "       [3.87050561e-04, 4.60932076e-01, 5.38680851e-01],\n",
              "       [3.26127447e-05, 5.93088791e-02, 9.40658510e-01],\n",
              "       [2.92617756e-06, 2.41778027e-02, 9.75819230e-01],\n",
              "       [4.77337107e-06, 1.29729379e-02, 9.87022281e-01],\n",
              "       [6.17311453e-05, 1.23056985e-01, 8.76881361e-01],\n",
              "       [4.31516120e-04, 3.87299687e-01, 6.12268746e-01],\n",
              "       [5.92230826e-05, 1.55892685e-01, 8.44048083e-01],\n",
              "       [3.77996298e-06, 1.34775406e-02, 9.86518621e-01],\n",
              "       [8.90512310e-05, 1.98567152e-01, 8.01343858e-01],\n",
              "       [2.29475445e-05, 3.04453336e-02, 9.69531775e-01],\n",
              "       [2.37213976e-06, 1.07831061e-02, 9.89214420e-01],\n",
              "       [2.78142829e-06, 1.07080704e-02, 9.89289165e-01],\n",
              "       [2.99556814e-05, 7.09196180e-02, 9.29050386e-01],\n",
              "       [5.22692426e-05, 8.10887441e-02, 9.18858945e-01],\n",
              "       [8.38225678e-05, 1.52129099e-01, 8.47787082e-01],\n",
              "       [1.52574939e-05, 3.17474231e-02, 9.68237340e-01],\n",
              "       [1.12863061e-04, 1.31034717e-01, 8.68852437e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print y\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4mlsB9fT4qy",
        "outputId": "9d4375d5-a500-4282-d144-cd4b363b2bb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The column (pred) with the highest probability is the prediction of the neural network.\n",
        "Use argmax function to find the index of the maximum prediction for each row."
      ],
      "metadata": {
        "id": "G2clT4Z4UCep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Usually the column (pred) with the highest prediction is considered to be the prediction of the neural network.  It is easy\n",
        "# to convert the predictions to the expected iris species.  The argmax function finds the index of the maximum prediction\n",
        "# for each row.\n",
        "\n",
        "predict_classes = np.argmax(pred,axis=1)\n",
        "\n",
        "true_classes = np.argmax(y,axis=1)\n",
        "\n",
        "print(\"Predictions: {}\".format(predict_classes))\n",
        "print(\"True: {}\".format(true_classes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-49iKzxUEAy",
        "outputId": "b3917f82-88dd-412e-b836-777d462b78b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1\n",
            " 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2]\n",
            "True: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Of course it is very easy to turn these indexes back into iris species.  We just use the species list that we created earlier.\n",
        "print(species[predict_classes[0:10]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1liuTVzUKvJ",
        "outputId": "b7934c73-711c-4692-a234-ac86eef728fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
            " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#For all of the iris predictions, what percent were correct?\n",
        "\n",
        "correct = metrics.accuracy_score(true_classes, predict_classes)\n",
        "print(\"Accuracy: {}\".format(correct))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNc5-Q-dUNbb",
        "outputId": "ed712def-7315-415f-f985-f0ff4b045f64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code below performs two ad hoc predictions.\n",
        "\n",
        "*** Remember x should be a 2D array! ***"
      ],
      "metadata": {
        "id": "hDt14LMKUQQx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ad hoc prediction\n",
        "sample_flower = np.array( [[5.0,3.0,4.0]], dtype=float)\n",
        "pred = np.argmax(pred)\n",
        "print(\"Predict that {} is: {}\".format(sample_flower,species[pred]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "FHq6SUEbUR2N",
        "outputId": "f2041f50-fb45-4454-d1fd-d4928115c129"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-7d784ed35763>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msample_flower\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Predict that {} is: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_flower\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mspecies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: index 42 is out of bounds for axis 0 with size 3"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predict two sample flowers\n",
        "sample_flower = np.array( [[5.0,3.0,4.0,2.0],[5.2,3.5,1.5,0.8]], dtype=float)\n",
        "pred = np.argmax(pred)\n",
        "print(\"Predict that {} is: {}\".format(sample_flower,species[pred]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MhqYmPWWMJ9",
        "outputId": "acf72bb3-680b-4f4a-eaa0-966cc9fcee30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predict that [[5.  3.  4.  2. ]\n",
            " [5.2 3.5 1.5 0.8]] is: Iris-setosa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load/Save Trained Network\n"
      ],
      "metadata": {
        "id": "qVOwuD61W1vy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Complex neural networks will take a long time to fit/train.  It is helpful to be able to save these neural networks so that they can be reloaded later.  A reloaded neural network will not require retraining.  Keras provides three formats for neural network saving.\n",
        "\n",
        "* **YAML** - Stores the neural network structure (no weights) in the [YAML file format](https://en.wikipedia.org/wiki/YAML).\n",
        "* **JSON** - Stores the neural network structure (no weights) in the [JSON file format](https://en.wikipedia.org/wiki/JSON).\n",
        "* **HDF5** - Stores the complete neural network (with weights) in the [HDF5 file format](https://en.wikipedia.org/wiki/Hierarchical_Data_Format).\n",
        "\n",
        "Usually you will want to save in HDF5."
      ],
      "metadata": {
        "id": "Kd4UOdkdW5id"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "import pandas as pd\n",
        "import io\n",
        "import requests\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "path = \"/content/drive/MyDrive/Colab Notebooks/CSC219-MachineLearning/labs/data\"\n",
        "save_path = \"/content/drive/MyDrive/Colab Notebooks/CSC219-MachineLearning/labs/data\"\n",
        "\n",
        "filename_read = os.path.join(path,\"auto-mpg.csv\")\n",
        "df = pd.read_csv(filename_read,na_values=['NA','?'])\n",
        "\n",
        "cars = df['name']\n",
        "df.drop('name',1,inplace=True)\n",
        "missing_median(df, 'horsepower')\n",
        "x,y = to_xy(df,\"mpg\")\n",
        "model = Sequential()\n",
        "model.add(Dense(50, input_dim=x.shape[1], activation='relu')) # Hidden 1\n",
        "model.add(Dense(25, activation='relu')) # Hidden 2\n",
        "model.add(Dense(1)) # Output\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "model.fit(x,y,verbose=0,epochs=100)\n",
        "\n",
        "# Predict\n",
        "pred = model.predict(x)\n",
        "\n",
        "# Measure RMSE error.  RMSE is common for regression.\n",
        "score = np.sqrt(metrics.mean_squared_error(pred,y))\n",
        "print(\"Before save score (RMSE): {}\".format(score))\n",
        "\n",
        "\n",
        "# save entire network to HDF5 (save everything)\n",
        "model.save(os.path.join(save_path,\"network.hdf5\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5s6EYXjBXEnq",
        "outputId": "a8a408b1-a1be-4774-9b2a-270dd41da516"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-39-a9c16b4fcf0e>:15: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
            "  df.drop('name',1,inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13/13 [==============================] - 0s 1ms/step\n",
            "Before save score (RMSE): 4.95494270324707\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we reload the network and perform another prediction. The RMSE should match the previous one exactly if the neural network was really saved and reloaded."
      ],
      "metadata": {
        "id": "wVcj-ILnXE9B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model2 = load_model(os.path.join(save_path,\"network.hdf5\"))\n",
        "pred = model2.predict(x)\n",
        "# Measure RMSE error.  RMSE is common for regression.\n",
        "score = np.sqrt(metrics.mean_squared_error(pred,y))\n",
        "print(\"After load score (RMSE): {}\".format(score))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLLT7zpmXFih",
        "outputId": "7d7d0e98-b480-4751-cb53-5788bb0a4507"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13/13 [==============================] - 0s 1ms/step\n",
            "After load score (RMSE): 4.95494270324707\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## References:\n"
      ],
      "metadata": {
        "id": "LzHJJQUlXFKj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "* [Google Colab](https://colab.research.google.com/) - Free web based platform that includes Python, Juypter Notebooks, and TensorFlow with free GPU support.  No setup needed.\n",
        "* [IBM Cognitive Class Labs](https://www.datascientistworkbench.com) - Free web based platform that includes Python, Juypter Notebooks, and TensorFlow.  No setup needed.\n",
        "* [Python Anaconda](https://www.continuum.io/downloads) - Python distribution that includes many data science packages, such as Numpy, Scipy, Scikit-Learn, Pandas, and much more.\n",
        "* [TensorFlow](https://www.tensorflow.org/) - Google's mathematics package for deep learning.\n",
        "* [Kaggle](https://www.kaggle.com/) - Competitive data science.  Good source of sample data.\n",
        "* T81-558: Applications of Deep Neural Networks. Instructor: [Jeff Heaton](https://sites.wustl.edu/jeffheaton/)"
      ],
      "metadata": {
        "id": "oPTSoFopXFxE"
      }
    }
  ]
}