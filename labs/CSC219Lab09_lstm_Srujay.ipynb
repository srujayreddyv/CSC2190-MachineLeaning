{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srujayreddyv/CSUS-CSC219-MachineLeaning/blob/main/labs/CSC219Lab09_lstm_Srujay.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0guLxMa2Wt_"
      },
      "source": [
        "# CSC 219 Machine Learning (Fall 2023)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpqViUcb2WuB"
      },
      "source": [
        "# Lab 9: Recurrent Neural Networks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxON8OaR2WuC"
      },
      "source": [
        "### Helpful Functions for Tensorflow (Little Gems)\n",
        "\n",
        "The following functions will be used with TensorFlow to help preprocess the data.  They allow you to build the feature vector for a neural network.\n",
        "\n",
        "* Predictors/Inputs\n",
        "    * Fill any missing inputs with the median for that column.  Use **missing_median**.\n",
        "    * Encode textual/categorical values with **encode_text_dummy**.\n",
        "    * Encode numeric values with **encode_numeric_zscore**.\n",
        "* Output\n",
        "    * Discard rows with missing outputs.\n",
        "    * Encode textual/categorical values with **encode_text_index**.\n",
        "    * Do not encode output numeric values.\n",
        "* Convert dataframe to numpy array to create feature vectors (x) and expected output (y) with **to_xy**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMUjleQh2WuD"
      },
      "outputs": [],
      "source": [
        "from collections.abc import Sequence\n",
        "from sklearn import preprocessing\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "\n",
        "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
        "def encode_text_dummy(df, name):\n",
        "    dummies = pd.get_dummies(df[name])\n",
        "    for x in dummies.columns:\n",
        "        dummy_name = \"{}-{}\".format(name, x)\n",
        "        df[dummy_name] = dummies[x]\n",
        "    df.drop(name, axis=1, inplace=True)\n",
        "\n",
        "\n",
        "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
        "def encode_text_index(df, name):\n",
        "    le = preprocessing.LabelEncoder()\n",
        "    df[name] = le.fit_transform(df[name])\n",
        "    return le.classes_\n",
        "\n",
        "\n",
        "# Encode a numeric column as zscores\n",
        "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
        "    if mean is None:\n",
        "        mean = df[name].mean()\n",
        "\n",
        "    if sd is None:\n",
        "        sd = df[name].std()\n",
        "\n",
        "    df[name] = (df[name] - mean) / sd\n",
        "\n",
        "\n",
        "# Convert all missing values in the specified column to the median\n",
        "def missing_median(df, name):\n",
        "    med = df[name].median()\n",
        "    df[name] = df[name].fillna(med)\n",
        "\n",
        "\n",
        "# Convert all missing values in the specified column to the default\n",
        "def missing_default(df, name, default_value):\n",
        "    df[name] = df[name].fillna(default_value)\n",
        "\n",
        "\n",
        "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
        "def to_xy(df, target):\n",
        "    result = []\n",
        "    for x in df.columns:\n",
        "        if x != target:\n",
        "            result.append(x)\n",
        "    # find out the type of the target column.\n",
        "    target_type = df[target].dtypes\n",
        "    target_type = target_type[0] if isinstance(target_type, Sequence) else target_type\n",
        "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
        "    if target_type in (np.int64, np.int32):\n",
        "        # Classification\n",
        "        dummies = pd.get_dummies(df[target])\n",
        "        return df[result].values.astype(np.float32), dummies.values.astype(np.float32)\n",
        "    else:\n",
        "        # Regression\n",
        "        return df[result].values.astype(np.float32), df[target].values.astype(np.float32)\n",
        "\n",
        "# Nicely formatted time string\n",
        "def hms_string(sec_elapsed):\n",
        "    h = int(sec_elapsed / (60 * 60))\n",
        "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
        "    s = sec_elapsed % 60\n",
        "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
        "\n",
        "\n",
        "# Regression chart.\n",
        "def chart_regression(pred,y,sort=True):\n",
        "    t = pd.DataFrame({'pred' : pred, 'y' : y.flatten()})\n",
        "    if sort:\n",
        "        t.sort_values(by=['y'],inplace=True)\n",
        "    a = plt.plot(t['y'].tolist(),label='expected')\n",
        "    b = plt.plot(t['pred'].tolist(),label='prediction')\n",
        "    plt.ylabel('output')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Remove all rows where the specified column is +/- sd standard deviations\n",
        "def remove_outliers(df, name, sd):\n",
        "    drop_rows = df.index[(np.abs(df[name] - df[name].mean()) >= (sd * df[name].std()))]\n",
        "    df.drop(drop_rows, axis=0, inplace=True)\n",
        "\n",
        "\n",
        "# Encode a column to a range between normalized_low and normalized_high.\n",
        "def encode_numeric_range(df, name, normalized_low=-1, normalized_high=1,\n",
        "                         data_low=None, data_high=None):\n",
        "    if data_low is None:\n",
        "        data_low = min(df[name])\n",
        "        data_high = max(df[name])\n",
        "\n",
        "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
        "               * (normalized_high - normalized_low) + normalized_low\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgAtpGne2WuE"
      },
      "source": [
        "## Recurrent Neural Networks (a network that can remember the past input)\n",
        "\n",
        "So far the neural networks that we’ve examined have always had forward connections.  ***these networks are called “feedforward.”***  \n",
        "\n",
        "In Recurrent neural networks, \"backward/recurrent connections\" are also allowed. A \"backward/recurrent connection\" occurs when a connection is formed between a neuron and a neuron at the same level or a neuron at a previous level.\n",
        "\n",
        "\n",
        "Most recurrent neural network architectures maintain \"state\" in the recurrent connections.  ***A recurrent neural network’s state acts as a short-term memory (context) for the neural network.***  Consequently, a recurrent neural network will not always produce the same output for a given input."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XX849Lo2WuF"
      },
      "source": [
        "## Therefore, RNN is good at predicting over sequentail data (a sequnce of vectors)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Jmzf2Vz2WuF"
      },
      "source": [
        "### Notice that if we want to ***predict something over a sequence***,  we need to ***sequence*** our data by adding a dimension.  \n",
        "\n",
        "### x should be of 3 dimensions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6fpXmv42WuF",
        "outputId": "21538247-728f-4994-f993-ed743497755a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(5, 5, 2)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = [\n",
        "    [[32,1383],[41,2928],[39,8823],[20,1252],[15,1532]],\n",
        "    [[35,8272],[32,1383],[41,2928],[39,8823],[20,1252]],\n",
        "    [[37,2738],[35,8272],[32,1383],[41,2928],[39,8823]],\n",
        "    [[34,2845],[37,2738],[35,8272],[32,1383],[41,2928]],\n",
        "    [[32,2345],[34,2845],[37,2738],[35,8272],[32,1383]],\n",
        "]\n",
        "\n",
        "y = [\n",
        "    1,\n",
        "    -1,\n",
        "    0,\n",
        "    -1,\n",
        "    1\n",
        "]\n",
        "\n",
        "np.array(x).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dhtiuCe2WuG"
      },
      "source": [
        "# LSTM layers in TensorFlow\n",
        "\n",
        "Long Short Term Neural Network (LSTM) are ***a type of recurrent unit***.  For TensorFlow, LSTM is provided as a layer type that can be combined with other layer types, such as dense.  \n",
        "\n",
        "https://keras.io/layers/recurrent/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rswv4IK_2WuG"
      },
      "source": [
        "# LSTM Example for Classification\n",
        "\n",
        "The following code creates the LSTM network.  This is an example of RNN classification.  The following code trains on a data set (x) with a max sequence size of 6 (columns) and 6 training elements (rows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hXbnKC0y2WuH",
        "outputId": "a67e3cb5-7345-4185-8900-676ae27b82b2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0.],\n",
              "       [0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0.],\n",
              "       [0., 0., 0., 1.],\n",
              "       [1., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding\n",
        "from tensorflow.keras.layers import LSTM\n",
        "\n",
        "# assume we have 4 classes\n",
        "num_classes = 4\n",
        "\n",
        "x = [\n",
        "    [[0],[1],[1],[0],[0],[0]],\n",
        "    [[0],[0],[0],[2],[2],[0]],\n",
        "    [[0],[0],[0],[0],[3],[3]],\n",
        "    [[0],[2],[2],[0],[0],[0]],\n",
        "    [[0],[0],[3],[3],[0],[0]],\n",
        "    [[0],[0],[0],[0],[1],[1]]\n",
        "]\n",
        "\n",
        "\n",
        "# Tensorflow likes float32 and int32\n",
        "x = np.array(x, dtype=np.float32)\n",
        "\n",
        "y = np.array([1,2,3,2,3,0], dtype=np.int32)\n",
        "\n",
        "\n",
        "# Convert y2to dummy variables (one-hot encoding for classification problem)\n",
        "\n",
        "y_2 = tf.keras.utils.to_categorical(y, num_classes)\n",
        "y_2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5DM4lbW2WuH"
      },
      "source": [
        "### Like CNN,  input_shape is the shape of each sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fTRMSIno2WuH",
        "outputId": "dee29ab5-fc31-4301-bac0-8f2f98afb55b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Build model...\n",
            "Train...\n",
            "Epoch 1/100\n",
            "1/1 - 0s - loss: 1.4084 - accuracy: 0.1667\n",
            "Epoch 2/100\n",
            "1/1 - 0s - loss: 1.3983 - accuracy: 0.5000\n",
            "Epoch 3/100\n",
            "1/1 - 0s - loss: 1.3939 - accuracy: 0.3333\n",
            "Epoch 4/100\n",
            "1/1 - 0s - loss: 1.3923 - accuracy: 0.3333\n",
            "Epoch 5/100\n",
            "1/1 - 0s - loss: 1.3812 - accuracy: 0.3333\n",
            "Epoch 6/100\n",
            "1/1 - 0s - loss: 1.3725 - accuracy: 0.3333\n",
            "Epoch 7/100\n",
            "1/1 - 0s - loss: 1.3711 - accuracy: 0.3333\n",
            "Epoch 8/100\n",
            "1/1 - 0s - loss: 1.3630 - accuracy: 0.3333\n",
            "Epoch 9/100\n",
            "1/1 - 0s - loss: 1.3554 - accuracy: 0.5000\n",
            "Epoch 10/100\n",
            "1/1 - 0s - loss: 1.3459 - accuracy: 0.5000\n",
            "Epoch 11/100\n",
            "1/1 - 0s - loss: 1.3359 - accuracy: 0.5000\n",
            "Epoch 12/100\n",
            "1/1 - 0s - loss: 1.3404 - accuracy: 0.5000\n",
            "Epoch 13/100\n",
            "1/1 - 0s - loss: 1.3240 - accuracy: 0.5000\n",
            "Epoch 14/100\n",
            "1/1 - 0s - loss: 1.3216 - accuracy: 0.5000\n",
            "Epoch 15/100\n",
            "1/1 - 0s - loss: 1.3191 - accuracy: 0.5000\n",
            "Epoch 16/100\n",
            "1/1 - 0s - loss: 1.3256 - accuracy: 0.3333\n",
            "Epoch 17/100\n",
            "1/1 - 0s - loss: 1.2939 - accuracy: 0.3333\n",
            "Epoch 18/100\n",
            "1/1 - 0s - loss: 1.2819 - accuracy: 0.5000\n",
            "Epoch 19/100\n",
            "1/1 - 0s - loss: 1.2730 - accuracy: 0.5000\n",
            "Epoch 20/100\n",
            "1/1 - 0s - loss: 1.2608 - accuracy: 0.5000\n",
            "Epoch 21/100\n",
            "1/1 - 0s - loss: 1.2589 - accuracy: 0.5000\n",
            "Epoch 22/100\n",
            "1/1 - 0s - loss: 1.2449 - accuracy: 0.3333\n",
            "Epoch 23/100\n",
            "1/1 - 0s - loss: 1.2364 - accuracy: 0.6667\n",
            "Epoch 24/100\n",
            "1/1 - 0s - loss: 1.2273 - accuracy: 0.5000\n",
            "Epoch 25/100\n",
            "1/1 - 0s - loss: 1.2548 - accuracy: 0.3333\n",
            "Epoch 26/100\n",
            "1/1 - 0s - loss: 1.2747 - accuracy: 0.1667\n",
            "Epoch 27/100\n",
            "1/1 - 0s - loss: 1.2008 - accuracy: 0.3333\n",
            "Epoch 28/100\n",
            "1/1 - 0s - loss: 1.2511 - accuracy: 0.6667\n",
            "Epoch 29/100\n",
            "1/1 - 0s - loss: 1.2334 - accuracy: 0.5000\n",
            "Epoch 30/100\n",
            "1/1 - 0s - loss: 1.1882 - accuracy: 0.5000\n",
            "Epoch 31/100\n",
            "1/1 - 0s - loss: 1.1755 - accuracy: 0.3333\n",
            "Epoch 32/100\n",
            "1/1 - 0s - loss: 1.2058 - accuracy: 0.3333\n",
            "Epoch 33/100\n",
            "1/1 - 0s - loss: 1.2533 - accuracy: 0.3333\n",
            "Epoch 34/100\n",
            "1/1 - 0s - loss: 1.1541 - accuracy: 0.5000\n",
            "Epoch 35/100\n",
            "1/1 - 0s - loss: 1.2038 - accuracy: 0.3333\n",
            "Epoch 36/100\n",
            "1/1 - 0s - loss: 1.2080 - accuracy: 0.3333\n",
            "Epoch 37/100\n",
            "1/1 - 0s - loss: 1.1604 - accuracy: 0.5000\n",
            "Epoch 38/100\n",
            "1/1 - 0s - loss: 1.0897 - accuracy: 0.6667\n",
            "Epoch 39/100\n",
            "1/1 - 0s - loss: 1.2494 - accuracy: 0.3333\n",
            "Epoch 40/100\n",
            "1/1 - 0s - loss: 1.1124 - accuracy: 0.6667\n",
            "Epoch 41/100\n",
            "1/1 - 0s - loss: 1.1738 - accuracy: 0.3333\n",
            "Epoch 42/100\n",
            "1/1 - 0s - loss: 1.1276 - accuracy: 0.5000\n",
            "Epoch 43/100\n",
            "1/1 - 0s - loss: 1.1433 - accuracy: 0.5000\n",
            "Epoch 44/100\n",
            "1/1 - 0s - loss: 1.0310 - accuracy: 0.5000\n",
            "Epoch 45/100\n",
            "1/1 - 0s - loss: 1.1007 - accuracy: 0.5000\n",
            "Epoch 46/100\n",
            "1/1 - 0s - loss: 1.1885 - accuracy: 0.3333\n",
            "Epoch 47/100\n",
            "1/1 - 0s - loss: 1.0692 - accuracy: 0.5000\n",
            "Epoch 48/100\n",
            "1/1 - 0s - loss: 1.0426 - accuracy: 0.5000\n",
            "Epoch 49/100\n",
            "1/1 - 0s - loss: 1.0656 - accuracy: 0.5000\n",
            "Epoch 50/100\n",
            "1/1 - 0s - loss: 1.0568 - accuracy: 0.5000\n",
            "Epoch 51/100\n",
            "1/1 - 0s - loss: 1.1053 - accuracy: 0.5000\n",
            "Epoch 52/100\n",
            "1/1 - 0s - loss: 1.2562 - accuracy: 0.3333\n",
            "Epoch 53/100\n",
            "1/1 - 0s - loss: 0.9814 - accuracy: 0.5000\n",
            "Epoch 54/100\n",
            "1/1 - 0s - loss: 0.9602 - accuracy: 0.6667\n",
            "Epoch 55/100\n",
            "1/1 - 0s - loss: 1.0252 - accuracy: 0.5000\n",
            "Epoch 56/100\n",
            "1/1 - 0s - loss: 1.0510 - accuracy: 0.5000\n",
            "Epoch 57/100\n",
            "1/1 - 0s - loss: 1.0531 - accuracy: 0.5000\n",
            "Epoch 58/100\n",
            "1/1 - 0s - loss: 0.9598 - accuracy: 0.5000\n",
            "Epoch 59/100\n",
            "1/1 - 0s - loss: 0.9981 - accuracy: 0.6667\n",
            "Epoch 60/100\n",
            "1/1 - 0s - loss: 1.2092 - accuracy: 0.3333\n",
            "Epoch 61/100\n",
            "1/1 - 0s - loss: 1.0582 - accuracy: 0.5000\n",
            "Epoch 62/100\n",
            "1/1 - 0s - loss: 1.0382 - accuracy: 0.5000\n",
            "Epoch 63/100\n",
            "1/1 - 0s - loss: 1.0167 - accuracy: 0.6667\n",
            "Epoch 64/100\n",
            "1/1 - 0s - loss: 1.0013 - accuracy: 0.5000\n",
            "Epoch 65/100\n",
            "1/1 - 0s - loss: 0.9142 - accuracy: 0.5000\n",
            "Epoch 66/100\n",
            "1/1 - 0s - loss: 0.8699 - accuracy: 0.5000\n",
            "Epoch 67/100\n",
            "1/1 - 0s - loss: 0.8729 - accuracy: 0.5000\n",
            "Epoch 68/100\n",
            "1/1 - 0s - loss: 0.9390 - accuracy: 0.5000\n",
            "Epoch 69/100\n",
            "1/1 - 0s - loss: 1.0679 - accuracy: 0.5000\n",
            "Epoch 70/100\n",
            "1/1 - 0s - loss: 0.9788 - accuracy: 0.5000\n",
            "Epoch 71/100\n",
            "1/1 - 0s - loss: 0.8879 - accuracy: 0.5000\n",
            "Epoch 72/100\n",
            "1/1 - 0s - loss: 0.7718 - accuracy: 0.6667\n",
            "Epoch 73/100\n",
            "1/1 - 0s - loss: 0.8285 - accuracy: 0.5000\n",
            "Epoch 74/100\n",
            "1/1 - 0s - loss: 0.8882 - accuracy: 0.5000\n",
            "Epoch 75/100\n",
            "1/1 - 0s - loss: 1.1166 - accuracy: 0.3333\n",
            "Epoch 76/100\n",
            "1/1 - 0s - loss: 0.7382 - accuracy: 0.6667\n",
            "Epoch 77/100\n",
            "1/1 - 0s - loss: 1.0456 - accuracy: 0.5000\n",
            "Epoch 78/100\n",
            "1/1 - 0s - loss: 1.0405 - accuracy: 0.3333\n",
            "Epoch 79/100\n",
            "1/1 - 0s - loss: 0.8496 - accuracy: 0.5000\n",
            "Epoch 80/100\n",
            "1/1 - 0s - loss: 0.9837 - accuracy: 0.5000\n",
            "Epoch 81/100\n",
            "1/1 - 0s - loss: 0.9930 - accuracy: 0.5000\n",
            "Epoch 82/100\n",
            "1/1 - 0s - loss: 0.8750 - accuracy: 0.5000\n",
            "Epoch 83/100\n",
            "1/1 - 0s - loss: 0.7366 - accuracy: 0.5000\n",
            "Epoch 84/100\n",
            "1/1 - 0s - loss: 0.7933 - accuracy: 0.5000\n",
            "Epoch 85/100\n",
            "1/1 - 0s - loss: 0.7358 - accuracy: 0.5000\n",
            "Epoch 86/100\n",
            "1/1 - 0s - loss: 0.8215 - accuracy: 0.5000\n",
            "Epoch 87/100\n",
            "1/1 - 0s - loss: 0.6459 - accuracy: 0.8333\n",
            "Epoch 88/100\n",
            "1/1 - 0s - loss: 0.8573 - accuracy: 0.5000\n",
            "Epoch 89/100\n",
            "1/1 - 0s - loss: 1.0236 - accuracy: 0.5000\n",
            "Epoch 90/100\n",
            "1/1 - 0s - loss: 0.8248 - accuracy: 0.5000\n",
            "Epoch 91/100\n",
            "1/1 - 0s - loss: 0.6741 - accuracy: 0.5000\n",
            "Epoch 92/100\n",
            "1/1 - 0s - loss: 0.9988 - accuracy: 0.5000\n",
            "Epoch 93/100\n",
            "1/1 - 0s - loss: 0.9718 - accuracy: 0.5000\n",
            "Epoch 94/100\n",
            "1/1 - 0s - loss: 0.6960 - accuracy: 0.5000\n",
            "Epoch 95/100\n",
            "1/1 - 0s - loss: 0.7068 - accuracy: 0.5000\n",
            "Epoch 96/100\n",
            "1/1 - 0s - loss: 0.6528 - accuracy: 0.6667\n",
            "Epoch 97/100\n",
            "1/1 - 0s - loss: 0.8755 - accuracy: 0.3333\n",
            "Epoch 98/100\n",
            "1/1 - 0s - loss: 0.9496 - accuracy: 0.5000\n",
            "Epoch 99/100\n",
            "1/1 - 0s - loss: 1.0973 - accuracy: 0.3333\n",
            "Epoch 100/100\n",
            "1/1 - 0s - loss: 0.7459 - accuracy: 0.5000\n",
            "Predicted classes: [2 3 3 2 3 0]\n",
            "Expected classes: [1 2 3 2 3 0]\n"
          ]
        }
      ],
      "source": [
        "# If numpy 1.20 gives you error, you may want to downgrade using pip install numpy==1.19.2\n",
        "\n",
        "print('Build model...')\n",
        "model = Sequential()\n",
        "\n",
        "# each sequence has 6 members and each member is 1-dimentinal\n",
        "\n",
        "#Like CNN,  input_shape is the shape of each sample\n",
        "\n",
        "model.add(LSTM(128, activation='relu', dropout=0.2, recurrent_dropout=0.2, input_shape=(6, 1)))\n",
        "model.add(Dense(4, activation='softmax'))\n",
        "\n",
        "# try using different optimizers and different optimizer configs\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "print('Train...')\n",
        "model.fit(x, y_2,verbose=2, epochs=100)\n",
        "pred = model.predict(x)\n",
        "\n",
        "predict_classes = np.argmax(pred,axis=1)\n",
        "print(\"Predicted classes:\",predict_classes)\n",
        "print(\"Expected classes:\",y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S48xEqON2WuH"
      },
      "source": [
        "### Let's predict any ad hoc sequence using trained model\n",
        "\n",
        "For example  [[0],[0],[0],[0],[0],[1]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cCaAqWlv2WuH",
        "outputId": "1c34f141-382d-427a-b127-9b7dcbe7730a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(6, 1)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = np.array([[0],[0],[0],[0],[0],[1]])\n",
        "\n",
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "geNfCSua2WuI",
        "outputId": "868313d3-8d79-4c84-b639-921f0cf4d6f2"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "in user code:\n\n    c:\\Users\\haiquan.chen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1462 predict_function  *\n        return step_function(self, iterator)\n    c:\\Users\\haiquan.chen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1452 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    c:\\Users\\haiquan.chen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    c:\\Users\\haiquan.chen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    c:\\Users\\haiquan.chen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    c:\\Users\\haiquan.chen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1445 run_step  **\n        outputs = model.predict_step(data)\n    c:\\Users\\haiquan.chen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1418 predict_step\n        return self(x, training=False)\n    c:\\Users\\haiquan.chen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:975 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs,\n    c:\\Users\\haiquan.chen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:176 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\n    ValueError: Input 0 of layer sequential is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: [None, 1]\n",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-7-21854b1e4784>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\haiquan.chen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[0;32m    129\u001b[0m           method.__name__))\n\u001b[1;32m--> 130\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m   return tf_decorator.make_decorator(\n",
            "\u001b[1;32mc:\\Users\\haiquan.chen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1597\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1598\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1599\u001b[1;33m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1600\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1601\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\haiquan.chen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\haiquan.chen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    812\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 814\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    815\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[1;32mc:\\Users\\haiquan.chen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2826\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2828\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2829\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\haiquan.chen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3208\u001b[0m           \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_signature\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3209\u001b[0m           and call_context_key in self._function_cache.missed):\n\u001b[1;32m-> 3210\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_define_function_with_shape_relaxation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\haiquan.chen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3139\u001b[0m           expand_composites=True)\n\u001b[0;32m   3140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3141\u001b[1;33m     graph_function = self._create_graph_function(\n\u001b[0m\u001b[0;32m   3142\u001b[0m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0;32m   3143\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\haiquan.chen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3063\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3064\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3065\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3066\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3067\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\haiquan.chen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\haiquan.chen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    598\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\haiquan.chen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    971\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    972\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 973\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    974\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    c:\\Users\\haiquan.chen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1462 predict_function  *\n        return step_function(self, iterator)\n    c:\\Users\\haiquan.chen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1452 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    c:\\Users\\haiquan.chen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    c:\\Users\\haiquan.chen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    c:\\Users\\haiquan.chen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    c:\\Users\\haiquan.chen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1445 run_step  **\n        outputs = model.predict_step(data)\n    c:\\Users\\haiquan.chen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1418 predict_step\n        return self(x, training=False)\n    c:\\Users\\haiquan.chen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:975 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs,\n    c:\\Users\\haiquan.chen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:176 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\n    ValueError: Input 0 of layer sequential is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: [None, 1]\n"
          ]
        }
      ],
      "source": [
        "x = np.array(x, dtype=np.float32)\n",
        "\n",
        "pred = model.predict(x)\n",
        "\n",
        "print(x)\n",
        "\n",
        "print(\"Prediction:\", np.argmax(pred[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVxbODku2WuI"
      },
      "source": [
        "### Why?  \n",
        "\n",
        "### Remeber x must be a 3D array!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5XVd1XeI2WuI",
        "outputId": "00fbbaf6-5ada-40e5-bd74-d0f60b11da2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1, 6, 1)\n",
            "Prediction: 0\n"
          ]
        }
      ],
      "source": [
        "x = np.array([[[0],[0],[0],[0],[0],[1]]])\n",
        "\n",
        "x = np.array(x, dtype=np.float32)\n",
        "\n",
        "pred = model.predict(x)\n",
        "\n",
        "print(x.shape)\n",
        "\n",
        "print(\"Prediction:\", np.argmax(pred[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVAevBaQ2WuJ"
      },
      "source": [
        "# LSTM Example for Regression\n",
        "\n",
        "An example of RNN regression to predict sunspots.  The data files needed for this example can be found at the following location.\n",
        "\n",
        "* [Sunspot Data Files](http://www.sidc.be/silso/datafiles#total)\n",
        "\n",
        "http://www.sidc.be/silso/infosndtot\n",
        "\n",
        "The following code is used to load the sunspot file:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Rdrr03v2WuJ",
        "outputId": "101e46f6-cdf9-4c73-cfe8-56e15e06fb85"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>dec_year</th>\n",
              "      <th>sn_value</th>\n",
              "      <th>sn_error</th>\n",
              "      <th>obs_num</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1818</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1818.001</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1818</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1818.004</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1818</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1818.007</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1818</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1818.010</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1818</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1818.012</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1818</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1818.015</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1818</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1818.018</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1818</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>1818.021</td>\n",
              "      <td>65</td>\n",
              "      <td>10.2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1818</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>1818.023</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1818</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>1818.026</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   year  month  day  dec_year  sn_value  sn_error  obs_num\n",
              "0  1818      1    1  1818.001        -1      -1.0        0\n",
              "1  1818      1    2  1818.004        -1      -1.0        0\n",
              "2  1818      1    3  1818.007        -1      -1.0        0\n",
              "3  1818      1    4  1818.010        -1      -1.0        0\n",
              "4  1818      1    5  1818.012        -1      -1.0        0\n",
              "5  1818      1    6  1818.015        -1      -1.0        0\n",
              "6  1818      1    7  1818.018        -1      -1.0        0\n",
              "7  1818      1    8  1818.021        65      10.2        1\n",
              "8  1818      1    9  1818.023        -1      -1.0        0\n",
              "9  1818      1   10  1818.026        -1      -1.0        0"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "path = \"./data/\"\n",
        "\n",
        "filename = os.path.join(path,\"SN_d_tot_V2.0.csv\")\n",
        "names = ['year', 'month', 'day', 'dec_year', 'sn_value' , 'sn_error', 'obs_num']\n",
        "df = pd.read_csv(filename, sep=';', header=None, names=names, index_col=False)\n",
        "\n",
        "# index_col=False forces pandas not to use the first column as the index\n",
        "\n",
        "df[0:10]\n",
        "\n",
        "# -1 means NA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rIieE5qw2WuJ"
      },
      "outputs": [],
      "source": [
        "# The missing values are marked by -1\n",
        "\n",
        "df = df[(df['sn_value'] != -1) & (df['obs_num'] != 0)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ilP5LLpp2WuK",
        "outputId": "4f939199-8106-4dd9-e221-a1598dfc7eae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(69922, 7)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6zZQjroT2WuK",
        "outputId": "ee2aa192-0a53-46a0-e06c-0accbb6976af"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>dec_year</th>\n",
              "      <th>sn_value</th>\n",
              "      <th>sn_error</th>\n",
              "      <th>obs_num</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1818</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>1818.021</td>\n",
              "      <td>65</td>\n",
              "      <td>10.2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1818</td>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>1818.034</td>\n",
              "      <td>37</td>\n",
              "      <td>7.7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1818</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>1818.045</td>\n",
              "      <td>77</td>\n",
              "      <td>11.1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1818</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>1818.048</td>\n",
              "      <td>98</td>\n",
              "      <td>12.6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1818</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>1818.051</td>\n",
              "      <td>105</td>\n",
              "      <td>13.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>1818</td>\n",
              "      <td>1</td>\n",
              "      <td>25</td>\n",
              "      <td>1818.067</td>\n",
              "      <td>25</td>\n",
              "      <td>6.3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>1818</td>\n",
              "      <td>1</td>\n",
              "      <td>28</td>\n",
              "      <td>1818.075</td>\n",
              "      <td>38</td>\n",
              "      <td>7.8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>1818</td>\n",
              "      <td>1</td>\n",
              "      <td>29</td>\n",
              "      <td>1818.078</td>\n",
              "      <td>20</td>\n",
              "      <td>5.7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>1818</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1818.092</td>\n",
              "      <td>17</td>\n",
              "      <td>5.2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>1818</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>1818.097</td>\n",
              "      <td>20</td>\n",
              "      <td>5.7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>1818</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>1818.100</td>\n",
              "      <td>25</td>\n",
              "      <td>6.3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>1818</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>1818.108</td>\n",
              "      <td>87</td>\n",
              "      <td>11.8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>1818</td>\n",
              "      <td>2</td>\n",
              "      <td>13</td>\n",
              "      <td>1818.119</td>\n",
              "      <td>192</td>\n",
              "      <td>17.5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>1818</td>\n",
              "      <td>2</td>\n",
              "      <td>14</td>\n",
              "      <td>1818.122</td>\n",
              "      <td>73</td>\n",
              "      <td>10.8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>1818</td>\n",
              "      <td>2</td>\n",
              "      <td>15</td>\n",
              "      <td>1818.125</td>\n",
              "      <td>82</td>\n",
              "      <td>11.4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    year  month  day  dec_year  sn_value  sn_error  obs_num\n",
              "7   1818      1    8  1818.021        65      10.2        1\n",
              "12  1818      1   13  1818.034        37       7.7        1\n",
              "16  1818      1   17  1818.045        77      11.1        1\n",
              "17  1818      1   18  1818.048        98      12.6        1\n",
              "18  1818      1   19  1818.051       105      13.0        1\n",
              "24  1818      1   25  1818.067        25       6.3        1\n",
              "27  1818      1   28  1818.075        38       7.8        1\n",
              "28  1818      1   29  1818.078        20       5.7        1\n",
              "33  1818      2    3  1818.092        17       5.2        1\n",
              "35  1818      2    5  1818.097        20       5.7        1\n",
              "36  1818      2    6  1818.100        25       6.3        1\n",
              "39  1818      2    9  1818.108        87      11.8        1\n",
              "43  1818      2   13  1818.119       192      17.5        1\n",
              "44  1818      2   14  1818.122        73      10.8        1\n",
              "45  1818      2   15  1818.125        82      11.4        1"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[0:15]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFdJD15q2WuK"
      },
      "source": [
        "### Now, we want to predict a SN value based on the $N$ preceding values.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MXbqI3kL2WuK",
        "outputId": "3347a6ad-4274-4ba3-e89a-0e926f89b244"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set has 63227 records.\n",
            "Test set has 6695 records.\n"
          ]
        }
      ],
      "source": [
        "df_train = df[df['year']<2000]\n",
        "df_test = df[df['year']>=2000]\n",
        "\n",
        "spots_train = df_train['sn_value'].tolist()\n",
        "spots_test = df_test['sn_value'].tolist()\n",
        "\n",
        "print(\"Training set has {} records.\".format(len(spots_train)))\n",
        "print(\"Test set has {} records.\".format(len(spots_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaWhATBK2WuK"
      },
      "source": [
        "### Sequence data to create x and y in the format RNN likes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iniOtkVs2WuL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def to_sequences(seq_size, data):\n",
        "    x = []\n",
        "    y = []\n",
        "\n",
        "    for i in range(len(data)-SEQUENCE_SIZE-1):\n",
        "        #print(i)\n",
        "        window = data[i:(i+SEQUENCE_SIZE)]\n",
        "        after_window = data[i+SEQUENCE_SIZE]\n",
        "        window = [[x] for x in window]\n",
        "        #print(\"{} - {}\".format(window,after_window))\n",
        "        x.append(window)\n",
        "        y.append(after_window)\n",
        "\n",
        "    return np.array(x),np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8z7q0cbF2WuL",
        "outputId": "35f233d3-fde4-4d1b-859f-1200aa2b6800"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of x_train: (63216, 10, 1)\n",
            "Shape of x_test: (6684, 10, 1)\n",
            "Shape of y_train: (63216,)\n",
            "Shape of y_test: (6684,)\n"
          ]
        }
      ],
      "source": [
        "SEQUENCE_SIZE = 10\n",
        "x_train,y_train = to_sequences(SEQUENCE_SIZE,spots_train)\n",
        "x_test,y_test = to_sequences(SEQUENCE_SIZE,spots_test)\n",
        "\n",
        "print(\"Shape of x_train: {}\".format(x_train.shape))\n",
        "print(\"Shape of x_test: {}\".format(x_test.shape))\n",
        "print(\"Shape of y_train: {}\".format(y_train.shape))\n",
        "print(\"Shape of y_test: {}\".format(y_test.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQrVJoGL2WuL",
        "outputId": "a3c7c81b-bc63-40d3-a457-81e88a98b938"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[[ 65],\n",
              "        [ 37],\n",
              "        [ 77],\n",
              "        [ 98],\n",
              "        [105],\n",
              "        [ 25],\n",
              "        [ 38],\n",
              "        [ 20],\n",
              "        [ 17],\n",
              "        [ 20]],\n",
              "\n",
              "       [[ 37],\n",
              "        [ 77],\n",
              "        [ 98],\n",
              "        [105],\n",
              "        [ 25],\n",
              "        [ 38],\n",
              "        [ 20],\n",
              "        [ 17],\n",
              "        [ 20],\n",
              "        [ 25]],\n",
              "\n",
              "       [[ 77],\n",
              "        [ 98],\n",
              "        [105],\n",
              "        [ 25],\n",
              "        [ 38],\n",
              "        [ 20],\n",
              "        [ 17],\n",
              "        [ 20],\n",
              "        [ 25],\n",
              "        [ 87]],\n",
              "\n",
              "       [[ 98],\n",
              "        [105],\n",
              "        [ 25],\n",
              "        [ 38],\n",
              "        [ 20],\n",
              "        [ 17],\n",
              "        [ 20],\n",
              "        [ 25],\n",
              "        [ 87],\n",
              "        [192]],\n",
              "\n",
              "       [[105],\n",
              "        [ 25],\n",
              "        [ 38],\n",
              "        [ 20],\n",
              "        [ 17],\n",
              "        [ 20],\n",
              "        [ 25],\n",
              "        [ 87],\n",
              "        [192],\n",
              "        [ 73]]])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train[0:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZgAlFraw2WuL",
        "outputId": "eab9182e-09d4-4f3d-a68f-7c713d9e05bf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 25,  87, 192,  73,  82])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train[0:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yx99hACD2WuL"
      },
      "source": [
        "### Ready to train a RNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-IUI8pe2WuM",
        "outputId": "edb7d968-ba18-4686-d833-473c182846bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Build model...\n",
            "Train...\n",
            "Epoch 1/3\n",
            "1976/1976 - 8s - loss: 1348.4918 - val_loss: 433.0674\n",
            "Epoch 2/3\n",
            "1976/1976 - 8s - loss: 621.8448 - val_loss: 239.1213\n",
            "Epoch 3/3\n",
            "1976/1976 - 7s - loss: 618.8212 - val_loss: 414.4273\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x26b547c0a90>"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import numpy as np\n",
        "\n",
        "print('Build model...')\n",
        "model = Sequential()\n",
        "\n",
        "model.add(LSTM(64, dropout=0.1, recurrent_dropout=0.1, input_shape=(SEQUENCE_SIZE, 1)))\n",
        "model.add(Dense(32))\n",
        "model.add(Dense(1))\n",
        "\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
        "print('Train...')\n",
        "\n",
        "model.fit(x_train,y_train,validation_data=(x_test,y_test), callbacks=[monitor],verbose=2, epochs=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FnFyUhfr2WuM",
        "outputId": "4acf6093-0bc2-4875-bb99-1158cd9d8f73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Score (RMSE): 20.35748903345908\n"
          ]
        }
      ],
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "pred = model.predict(x_test)\n",
        "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
        "print(\"Score (RMSE): {}\".format(score))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmzyd-Nv2WuM"
      },
      "source": [
        "## Stacking Several LSTM Layers\n",
        "\n",
        "https://keras.io/layers/recurrent/\n",
        "\n",
        "\n",
        "### Accessing the hidden state output   $\\hat{y}$  for each time slice\n",
        "\n",
        "\n",
        "It is possible to access the hidden state output $\\hat{y}$ (the cell output) for each time slice, which can be useful when developing sophisticated recurrent neural network architectures, such as the encoder-decoder model. This can be done by setting the ***return_sequences parameter to True*** when defining the LSTM layer\n",
        "\n",
        "***You must set return_sequences=True when stacking multiple LSTM layers.***\n",
        "\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(LSTM(..., return_sequences=True, input_shape=(...)))\n",
        "\n",
        "model.add(LSTM(..., return_sequences=True))\n",
        "\n",
        "model.add(LSTM(..., return_sequences=True))\n",
        "\n",
        "model.add(LSTM(...))\n",
        "\n",
        "model.add(Dense(...))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IxL1TTW2WuN"
      },
      "source": [
        "### Accessing the context values (internal state) $c$ for each time slice\n",
        "\n",
        "***the return_state argument provides access to the context values (internal state) $c$ for each time slice***\n",
        "\n",
        "\n",
        "For example, we can access both the sequence of hidden state output and the internal states at the same time.\n",
        "\n",
        "This can be done as follows:\n",
        "\n",
        "LSTM(..., return_sequences=True, return_state=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rKTC5oLH2WuN"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adv55g8o2WuN"
      },
      "source": [
        "### Loading the IMDB Reviews Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uo-WfqM82WuN"
      },
      "source": [
        "IMDB Reviews Dataset can be downloaded from the built-in datasets in Keras.  There are 25,000 samples of movie reviews for training and 25,000 samples for validation. Setting `max_features` to 20,000 means we are only considering the first 20,000 words and the rest of the words will have the out-of-vocabulary token. Each movie review has a positive or negative label.\n",
        "\n",
        "The training and validation datasets will be loaded as lists with 25,000 elements."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9osBjSQ2WuN"
      },
      "outputs": [],
      "source": [
        "max_features = 20000\n",
        "\n",
        "(train_data, train_labels), (val_data, val_labels) = tf.keras.datasets.imdb.load_data(num_words=max_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EB5jSMRq2WuO"
      },
      "source": [
        "Displayed below is the third movie review. It is also a list, it contains 141 words, and as we can see the words in the dataset are already converted to tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xSuCZnuG2WuO",
        "outputId": "b1a67c14-fa72-4485-ee38-a22be18ae992"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of words in the third review 141\n",
            "[1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 2, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 2, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]\n"
          ]
        }
      ],
      "source": [
        "# Display the third movie review\n",
        "print('Number of words in the third review', len(train_data[2]))\n",
        "print(train_data[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FxqS6C-z2WuO",
        "outputId": "85938d6b-8ea5-4dbb-a6e0-ae984248687a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 0, 0, 1, 0, 0, 1, 0, 1, 0], dtype=int64)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Display the first 10 labels\n",
        "train_labels[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUPbR5dR2WuO"
      },
      "source": [
        "### Preparing the Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWZJzg_E2WuO"
      },
      "source": [
        "Let's pad the data using the `pad_sequences` function in Keras. Setting `maxlen` indicates to use the first 200 words in each movie review, and ignore the rest. Most movie reviews in the dataset are shorter than 200 words, however for those that are longer than 200 words some information will be lost. That is a tradeoff between computational expense and model performance.\n",
        "\n",
        "We can see in the next cell that for the third reivew, which has a length of 141 words, the first 59 words are now 0, and the length is 200."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n9x9zWnL2WuO"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "train_data = pad_sequences(train_data, maxlen=200, padding='post')\n",
        "val_data = pad_sequences(val_data, maxlen=200, padding='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_fchyt1I2WuO",
        "outputId": "783c6f07-e625-4eb0-c62b-8e504929636d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of the third padded review: (200,) \n",
            "\n",
            "[   1   14   47    8   30   31    7    4  249  108    7    4 5974   54\n",
            "   61  369   13   71  149   14   22  112    4 2401  311   12   16 3711\n",
            "   33   75   43 1829  296    4   86  320   35  534   19  263 4821 1301\n",
            "    4 1873   33   89   78   12   66   16    4  360    7    4   58  316\n",
            "  334   11    4 1716   43  645  662    8  257   85 1200   42 1228 2578\n",
            "   83   68 3912   15   36  165 1539  278   36   69    2  780    8  106\n",
            "   14 6905 1338   18    6   22   12  215   28  610   40    6   87  326\n",
            "   23 2300   21   23   22   12  272   40   57   31   11    4   22   47\n",
            "    6 2307   51    9  170   23  595  116  595 1352   13  191   79  638\n",
            "   89    2   14    9    8  106  607  624   35  534    6  227    7  129\n",
            "  113    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0]\n"
          ]
        }
      ],
      "source": [
        "# Display the third movie review\n",
        "print('Shape of the third padded review:', train_data[2].shape, '\\n')\n",
        "print(train_data[2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSbj0cpp2WuP"
      },
      "source": [
        "## Build and Compile the Model\n",
        "\n",
        "You can build multiple layer LSTM models by simply appending another `LSTM` layer in your `Sequential` model and enabling the `return_sequences` flag to `True`. This is because an `LSTM` layer expects a sequence input so if the previous layer is also an LSTM, then it should output a sequence as well. See the code cell below that demonstrates this flag in action. You'll notice that the output dimension is in 3 dimensions `(batch_size, timesteps, features)` when when `return_sequences` is True."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bw6wLbR32WuR"
      },
      "source": [
        "The next cell implements the stacked LSTM architecture."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pORKY_e02WuR",
        "outputId": "54ef306f-524d-4409-ab22-363b72d3ab17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 64)          1280000   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, None, 128)        66048     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 64)               41216     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,391,489\n",
            "Trainable params: 1,391,489\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Hyperparameters\n",
        "\n",
        "batch_size = 64\n",
        "timesteps = 200\n",
        "\n",
        "embedding_dim = 64\n",
        "lstm1_dim = 64\n",
        "lstm2_dim = 32\n",
        "dense_dim = 64\n",
        "\n",
        "# Build the model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=max_features, output_dim=embedding_dim),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm1_dim, return_sequences=True)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm2_dim)),\n",
        "    tf.keras.layers.Dense(dense_dim, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LSG_GjZC2WuS"
      },
      "outputs": [],
      "source": [
        "# Set the training parameters\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWxKpd5E2WuS"
      },
      "source": [
        "## Train the Model\n",
        "\n",
        "The additional LSTM layer will lengthen the training time compared to the previous lab. Given the default parameters we set, it will take around 2 minutes per epoch with the Colab GPU enabled."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wNOtvfy92WuS",
        "outputId": "11a74f07-5cec-4cac-ba4a-8a272a86ecf0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "16/16 [==============================] - 11s 401ms/step - loss: 0.6939 - accuracy: 0.5020 - val_loss: 0.6926 - val_accuracy: 0.5220\n",
            "Epoch 2/10\n",
            "16/16 [==============================] - 5s 312ms/step - loss: 0.6831 - accuracy: 0.6480 - val_loss: 0.6836 - val_accuracy: 0.5680\n",
            "Epoch 3/10\n",
            "16/16 [==============================] - 5s 302ms/step - loss: 0.5491 - accuracy: 0.8220 - val_loss: 0.7261 - val_accuracy: 0.5780\n",
            "Epoch 4/10\n",
            "16/16 [==============================] - 5s 304ms/step - loss: 0.1780 - accuracy: 0.9580 - val_loss: 0.8558 - val_accuracy: 0.6780\n",
            "Epoch 5/10\n",
            "16/16 [==============================] - 5s 307ms/step - loss: 0.0485 - accuracy: 0.9900 - val_loss: 1.0984 - val_accuracy: 0.6880\n",
            "Epoch 6/10\n",
            "16/16 [==============================] - 5s 340ms/step - loss: 0.0112 - accuracy: 0.9960 - val_loss: 1.2590 - val_accuracy: 0.6720\n",
            "Epoch 7/10\n",
            "16/16 [==============================] - 6s 351ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.3091 - val_accuracy: 0.6880\n",
            "Epoch 8/10\n",
            "16/16 [==============================] - 6s 352ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.3175 - val_accuracy: 0.7140\n",
            "Epoch 9/10\n",
            "16/16 [==============================] - 6s 357ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.3633 - val_accuracy: 0.7180\n",
            "Epoch 10/10\n",
            "16/16 [==============================] - 6s 355ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.4134 - val_accuracy: 0.7140\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(train_data[0:500], train_labels[0:500], validation_data = (val_data[0:500], val_labels[0:500]), epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQvbxxdW2WuS",
        "outputId": "43fdf5e0-efa8-4b8d-f177-27dc51915d00"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot utility\n",
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.plot(history.history['val_'+string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.legend([string, 'val_'+string])\n",
        "  plt.show()\n",
        "\n",
        "# Plot the accuracy and results\n",
        "plot_graphs(history, \"accuracy\")\n",
        "plot_graphs(history, \"loss\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtKzdRjj2WuS"
      },
      "source": [
        "### References:\n",
        "\n",
        "* [Google Colab](https://colab.research.google.com/) - Free web based platform that includes Python, Juypter Notebooks, and TensorFlow with free GPU support.  No setup needed.\n",
        "* [IBM Cognitive Class Labs](https://www.datascientistworkbench.com) - Free web based platform that includes Python, Juypter Notebooks, and TensorFlow.  No setup needed.\n",
        "* [Python Anaconda](https://www.continuum.io/downloads) - Python distribution that includes many data science packages, such as Numpy, Scipy, Scikit-Learn, Pandas, and much more.\n",
        "* [TensorFlow](https://www.tensorflow.org/) - Google's mathematics package for deep learning.\n",
        "* [Kaggle](https://www.kaggle.com/) - Competitive data science.  Good source of sample data.\n",
        "* T81-558: Applications of Deep Neural Networks. Instructor: [Jeff Heaton](https://sites.wustl.edu/jeffheaton/)"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "cea39816bfa6bd3c0a1f6664bad4835e3a909c2e2cb41a9f2c8a2752fd725301"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}